<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[如何更优雅地切换 Git 分支]]></title>
    <url>%2F2019%2F02%2F01%2Fhow-to-switch-git-branches-more-gracefully%2F</url>
    <content type="text"><![CDATA[在日常开发中，我们经常需要在不同的 Git 分支之间来回切换，特别是业务需求比较多的开发人员。在分支较多的情况下，切换分支时分支名的 tab 自动补全会比较糟糕，我们不免需要复制或手打分支名，那么有没有更优雅的方式了呢？ 为了提高切换 Git 分支的效率，我用 Golang 写了 git-checkout-branch 这个小工具，可以交互式的切换分支，并自带搜索功能，帮助你更优雅的进行分支切换。 概览Github 地址：https://github.com/royeo/git-checkout-branch ，欢迎 star。 说明： 使用箭头键 ↓ ↑ → ← 进行移动 使用 j 和 k 也可以上下移动 使用 / 切换搜索 安装使用 go get 安装 git checkout-branch 命令，确保 $GOPATH/bin 路径在 PATH 中。 go get -u github.com/royeo/git-checkout-branch 如果你正在使用 GO1.11 Module，使用以下命令进行安装： GO111MODULE=off go get -u github.com/royeo/git-checkout-branch 建议为 checkout-branch 设置别名，例如 cb，这样就可以直接使用 git cb 来进行分支切换。 git config --global alias.cb checkout-branch 帮助使用 git checkout-branch help 获取帮助信息。 Checkout git branches more efficiently.Usage: git checkout-branch [flags]Flags: -a, --all List both remote-tracking branches and local branches -r, --remotes List the remote-tracking branches -n, --number Set the number of branches displayed in the list (default 10) --hide-help Hide the help information]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Git</tag>
        <tag>Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 标准库 log 包]]></title>
    <url>%2F2019%2F01%2F18%2Fgolang-standard-library-log%2F</url>
    <content type="text"><![CDATA[Golang 标准库提供了一个简单的 log 包，方便我们记录日志。在平时写一些 demo 或小程序时，我们经常会用到 log 包，不过由于缺少结构化格式、日志级别等支持，在实际开发中则很少使用。log 包的设计非常简洁，想造轮子的同学可以参考下。 Log design一个简单的日志包应该有哪些功能呢？很容易想到以下几个： 可设置日志的输出目标 可设置日志的固定输出项 日志输出接收可变参数 输出日志时并发安全 所以标准库的 log 里设计了下面这样一个 Logger 结构体： // log.gotype Logger struct &#123; mu sync.Mutex // ensures atomic writes; protects the following fields prefix string // prefix to write at beginning of each line flag int // properties out io.Writer // destination for output buf []byte // for accumulating text to write&#125; out 属性是日志的输出目标，在 golang 中，很自然的可以想到使用 io.Writer 接口类型，与具体实现分离开。之所以不把 out 属性暴露出来，是因为需要保证 out 的写入和修改都是原子操作，其他属性同理。这里使用 sync.Mutex 互斥锁来保证原子操作： // log.gofunc (l *Logger) SetOutput(w io.Writer) &#123; l.mu.Lock() defer l.mu.Unlock() l.out = w&#125; prefix 会出现在每行日志的最开头，flag 则是紧随其后的一些日志记录属性，如日期、时间、文件名和行号等。当设置了 prefix 和 flag 之后，每一行输出的日志都会带上这些前缀。flag 通过按位或（|）的方式来设置多个属性，可设置的属性如下： // log.goconst ( Ldate = 1 &lt;&lt; iota // the date in the local time zone: 2009/01/23 Ltime // the time in the local time zone: 01:23:23 Lmicroseconds // microsecond resolution: 01:23:23.123123. assumes Ltime. Llongfile // full file name and line number: /a/b/c/d.go:23 Lshortfile // final file name element and line number: d.go:23. overrides Llongfile LUTC // if Ldate or Ltime is set, use UTC rather than the local time zone LstdFlags = Ldate | Ltime // initial values for the standard logger) buf 是日志写入内容的缓冲区，避免了每次写入都需要分配内存。 Log operation使用 log 包写日志的操作很简单，可以直接调用 log.Println，log.Printf 等函数，这些导出的函数会调用内部私有变量 std 的方法，std 是 Logger 结构体的一个实例，输出日志到 stderr。在包里定义一个私有的 Logger 实例，并进行一些通用的配置，可以提供一些开箱即用的函数，而不需要总是先 New 一个 Logger 实例。 // log.gofunc New(out io.Writer, prefix string, flag int) *Logger &#123; return &amp;Logger&#123;out: out, prefix: prefix, flag: flag&#125;&#125;var std = New(os.Stderr, "", LstdFlags)func Println(v ...interface&#123;&#125;) &#123; std.Output(2, fmt.Sprintln(v...))&#125; 可以看到 log.Println 实际调用了 std.Output 方法，该方法接收两个参数，一个是函数调用深度，一个是日志内容。 // log.gofunc (l *Logger) Output(calldepth int, s string) error &#123; now := time.Now() // get this early. var file string var line int l.mu.Lock() defer l.mu.Unlock() if l.flag&amp;(Lshortfile|Llongfile) != 0 &#123; // Release lock while getting caller info - it's expensive. l.mu.Unlock() var ok bool _, file, line, ok = runtime.Caller(calldepth) if !ok &#123; file = "???" line = 0 &#125; l.mu.Lock() &#125; l.buf = l.buf[:0] l.formatHeader(&amp;l.buf, now, file, line) l.buf = append(l.buf, s...) if len(s) == 0 || s[len(s)-1] != '\n' &#123; l.buf = append(l.buf, '\n') &#125; _, err := l.out.Write(l.buf) return err&#125; 如果 flag 设置了 Lshortfile 或 Llongfile 属性，Output 方法会调用 runtime.Caller 来获取打印日志操作所在的文件名和行号。calldepth 参数用来指定函数调用深度，调用链为：log.Println -&gt; std.Output -&gt; runtime.Caller，所以调用深度为2。注意这里在获取文件名和行号的时候，释放了互斥锁，原因是 runtime.Caller 可能会比较耗时，所以存在一个隐患：在这期间其他的 goroutine 是可以修改 Logger 实例的属性的。 接下来就是清空 buf，先对 prefix 和 flag 进行处理（l.formatHeader）并存入 buf，然后将日志内容也追加到 buf 中，最后调用 out 属性的 Write 方法输出日志。 Conclusion整个 log 包就 300 多行代码，功能非常简单，使用起来也很方便。对于标准库来说，考虑的更多的是简洁、通用，而对于后端服务来说，则需要考虑更多的东西，比如结构化日志、性能问题等。一般情况下，不建议在生产环境使用标准库的 log 包来输出日志。目前 Golang 有很多优秀的开源日志库，例如：zap、gokit/log、logrus 等，各有各的优势，我们可以针对不同场景选择不同的日志库来解决问题。另外，在使用日志库的时候，最好是能够使用一个日志的抽象（比如 interface），而不绑定具体的实现，这会方便我们后期更换其他日志库。]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab 搭建与 CI 配置]]></title>
    <url>%2F2018%2F11%2F10%2Fgitlab-build%2F</url>
    <content type="text"><![CDATA[最近有一个独立开发的 Golang 微服务需要上线，项目托管在内部的 GitLab 上，所以需要写一个 .gitlab-ci.yml 文件来走 CI。由于之前一直是在比较成熟的团队中，没有自己写过 GitLab 的 CI 配置，所以索性尝试下自己搭建 GitLab，然后配置一套 CI 来熟悉下。 搭建 GitLab搭建 GitLab 最简单的方式当然是使用 docker。GitLab 的 docker 镜像集成了 GitLab 在运行中需要的所有服务。 这里使用 docker-compose 来运行，方便修改参数： web: image: 'gitlab/gitlab-ce:latest' restart: always hostname: 'gitlab.example.com' environment: GITLAB_OMNIBUS_CONFIG: | external_url 'https://gitlab.example.com' # Add any other gitlab.rb configuration here, each on its own line ports: - '80:80' - '443:443' - '22:22' volumes: - '/srv/gitlab/config:/etc/gitlab' - '/srv/gitlab/logs:/var/log/gitlab' - '/srv/gitlab/data:/var/opt/gitlab' 这里需要注意 SSH、HTTP、HTTPS 的端口是否被占用，以及卷的位置 docker 是否有权限访问。例如，在 macOS 上，docker 没有 /srv 的权限，所以可以使用 /Users/Shared 目录替代 /srv。 在容器启动后，等 GitLab 初始化完成（需等待一会），就可以通过 http://localhost/ 访问了。 另外还有一些部署 GitLab 的方法，具体参考官方文档：Omnibus GitLab documentation。 配置 GitLabGitLab 的所有配置都在 /etc/gitlab/gitlab.rb 文件中，你可以在 docker 挂载的数据卷目录下去修改配置，也可以进入 docker 容器去修改： docker exec -it gitlab /bin/bash 在 GitLab 的配置中，你需要修改 external_url 配置项为一个有效的 url，这个 url 就是你的 GitLab 仓库的域名，也可以通过上面 docker-compose 文件中的 environment 来修改 external_url 配置项。没有域名的话可以先用 IP 地址。 还有很多其他的配置，如邮箱、HTTPS 等的配置就不多介绍了。详细配置参考官方文档：Configuration options。 在修改完配置后，需要重启 docker 容器： docker restart gitlab 搭建 GitLab RunnerGitLab 的 CI 需要安装 Gitlab Runner，Runner 负责运行 .gitlab-ci.yml 中定义的 job，并且将结果发送回 GitLab。 Runner 不建议和 GitLab 同时运行在一台机器上，因为 Runner 很消耗资源，一旦 CI 运行起来，就可以看到 Runner 的 CPU 使用率飙升，所以应该分开部署。如果只是想测试一下，也可以先在一台机器上试一下。 同样使用 docker 来运行 Runner： docker run -d --name gitlab-runner --restart always \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest 然后需要把 Runner 注册到刚刚搭建好的 GitLab 上： docker run --rm -t -i -v /srv/gitlab-runner/config:/etc/gitlab-runner --name gitlab-runner gitlab/gitlab-runner register \ --non-interactive \ --executor "docker" \ --docker-image alpine:3.7 \ --url "https://gitlab.com/" \ --registration-token "PROJECT_REGISTRATION_TOKEN" \ --description "docker-runner" \ --tag-list "docker,aws" \ --run-untagged \ --locked="false" 注册参数说明： –url： GitLab 的域名，如果还没有配置域名的话，可以先使用 IP 地址代替。 –registration-token： CI 的 token，需要从 GitLab 页面上获取，参考：Obtain a token。 –description Runner 的描述，稍后可以在 GitLab 的页面 Settings &gt; CI/CD &gt; Runners 那里看到该 Runner 的描述。 –tag-list Runner 的 tags，使用 tag 标记 Runner 后，在 .gitlab-ci.yml 中定义 job 时，就可以使用 tags 配置来指定运行这个 job 的 Runner。 –executor Runner 的执行器，推荐使用 docker，它拥有一个干净的构建环境，易于依赖管理。 –docker-image 如果你使用 docker 作为 executor，需要提供一个默认镜像，在 .gitlab-ci.yml 中没有定义镜像时使用。 .gitlab-ci.yml在搭建好 GitLab 和 Runner 后，就可以在 GitLab 上新建一个项目，然后写 CI 的配置文件 .gitlab-ci.yml 了，参考：Configuring .gitlab-ci.yml]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown 代码高亮的标记大全]]></title>
    <url>%2F2018%2F10%2F30%2Fmarkdown-syntax-highlight%2F</url>
    <content type="text"><![CDATA[用 markdown 写文档的话经常会用到代码的语法高亮，这里列出了常用的语法高亮标签，前面是标签，括号里是对应的文件扩展名。 Syntax Highlight Cucumber (‘*.feature’) abap (‘*.abap’) ada (‘.adb’, ‘.ads’, ‘*.ada’) ahk (‘.ahk’, ‘.ahkl’) apacheconf (‘.htaccess’, ‘apache.conf’, ‘apache2.conf’) applescript (‘*.applescript’) as (‘*.as’) as3 (‘*.as’) asy (‘*.asy’) bash (‘.sh’, ‘.ksh’, ‘.bash’, ‘.ebuild’, ‘*.eclass’) bat (‘.bat’, ‘.cmd’) befunge (‘*.befunge’) blitzmax (‘*.bmx’) boo (‘*.boo’) brainfuck (‘.bf’, ‘.b’) c (‘.c’, ‘.h’) cfm (‘.cfm’, ‘.cfml’, ‘*.cfc’) cheetah (‘.tmpl’, ‘.spt’) cl (‘.cl’, ‘.lisp’, ‘*.el’) clojure (‘.clj’, ‘.cljs’) cmake (‘*.cmake’, ‘CMakeLists.txt’) coffeescript (‘*.coffee’) console (‘*.sh-session’) control (‘control’) cpp (‘.cpp’, ‘.hpp’, ‘.c++’, ‘.h++’, ‘.cc’, ‘.hh’, ‘.cxx’, ‘.hxx’, ‘*.pde’) csharp (‘*.cs’) css (‘*.css’) cython (‘.pyx’, ‘.pxd’, ‘*.pxi’) d (‘.d’, ‘.di’) delphi (‘*.pas’) diff (‘.diff’, ‘.patch’) dpatch (‘.dpatch’, ‘.darcspatch’) duel (‘.duel’, ‘.jbst’) dylan (‘.dylan’, ‘.dyl’) erb (‘*.erb’) erl (‘*.erl-sh’) erlang (‘.erl’, ‘.hrl’) evoque (‘*.evoque’) factor (‘*.factor’) felix (‘.flx’, ‘.flxh’) fortran (‘.f’, ‘.f90’) gas (‘.s’, ‘.S’) genshi (‘*.kid’) glsl (‘.vert’, ‘.frag’, ‘*.geo’) gnuplot (‘.plot’, ‘.plt’) go (‘*.go’) groff (‘.(1234567)’, ‘.man’) haml (‘*.haml’) haskell (‘*.hs’) html (‘.html’, ‘.htm’, ‘.xhtml’, ‘.xslt’) hx (‘*.hx’) hybris (‘.hy’, ‘.hyb’) ini (‘.ini’, ‘.cfg’) io (‘*.io’) ioke (‘*.ik’) irc (‘*.weechatlog’) jade (‘*.jade’) java (‘*.java’) js (‘*.js’) jsp (‘*.jsp’) lhs (‘*.lhs’) llvm (‘*.ll’) logtalk (‘*.lgt’) lua (‘.lua’, ‘.wlua’) make (‘.mak’, ‘Makefile’, ‘makefile’, ‘Makefile.‘, ‘GNUmakefile’) mako (‘*.mao’) maql (‘*.maql’) mason (‘.mhtml’, ‘.mc’, ‘*.mi’, ‘autohandler’, ‘dhandler’) markdown (‘*.md’) modelica (‘*.mo’) modula2 (‘.def’, ‘.mod’) moocode (‘*.moo’) mupad (‘*.mu’) mxml (‘*.mxml’) myghty (‘*.myt’, ‘autodelegate’) nasm (‘.asm’, ‘.ASM’) newspeak (‘*.ns2’) objdump (‘*.objdump’) objectivec (‘*.m’) objectivej (‘*.j’) ocaml (‘.ml’, ‘.mli’, ‘.mll’, ‘.mly’) ooc (‘*.ooc’) perl (‘.pl’, ‘.pm’) php (‘.php’, ‘.php(345)’) postscript (‘.ps’, ‘.eps’) pot (‘.pot’, ‘.po’) pov (‘.pov’, ‘.inc’) prolog (‘.prolog’, ‘.pro’, ‘*.pl’) properties (‘*.properties’) protobuf (‘*.proto’) py3tb (‘*.py3tb’) pytb (‘*.pytb’) python (‘.py’, ‘.pyw’, ‘.sc’, ‘SConstruct’, ‘SConscript’, ‘.tac’) rb (‘.rb’, ‘.rbw’, ‘Rakefile’, ‘.rake’, ‘.gemspec’, ‘.rbx’, ‘.duby’) rconsole (‘*.Rout’) rebol (‘.r’, ‘.r3’) redcode (‘*.cw’) rhtml (‘*.rhtml’) rst (‘.rst’, ‘.rest’) sass (‘*.sass’) scala (‘*.scala’) scaml (‘*.scaml’) scheme (‘*.scm’) scss (‘*.scss’) smalltalk (‘*.st’) smarty (‘*.tpl’) sourceslist (‘sources.list’) splus (‘.S’, ‘.R’) sql (‘*.sql’) sqlite3 (‘*.sqlite3-console’) squidconf (‘squid.conf’) ssp (‘*.ssp’) tcl (‘*.tcl’) tcsh (‘.tcsh’, ‘.csh’) tex (‘.tex’, ‘.aux’, ‘*.toc’) text (‘*.txt’) v (‘.v’, ‘.sv’) vala (‘.vala’, ‘.vapi’) vbnet (‘.vb’, ‘.bas’) velocity (‘.vm’, ‘.fhtml’) vim (‘*.vim’, ‘.vimrc’) xml (‘.xml’, ‘.xsl’, ‘.rss’, ‘.xslt’, ‘.xsd’, ‘.wsdl’) xquery (‘.xqy’, ‘.xquery’) xslt (‘.xsl’, ‘.xslt’) yaml (‘.yaml’, ‘.yml’)]]></content>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《现代操作系统》第1章 习题]]></title>
    <url>%2F2018%2F10%2F14%2Fmodern-operating-systems-c1-exercise%2F</url>
    <content type="text"><![CDATA[1.什么是多道程序设计？ Multiprogramming is the rapid switching of the CPU between multiple processes in memory. It is commonly used to keep the CPU busy while one or more processes are doing I/O. 2.什么是SPOOLing？读者是否认为将来的高级个人计算机会把SPOOLing作为标准功能？ Input spooling is the technique of reading in jobs, for example, from cards, onto the disk, so that when the currently executing processes are finished, there will be work waiting for the CPU. Output spooling consists of first copying printable files to disk before printing them, rather than printing directly as the output is generated. Input spooling on a personal computer is not very likely, but output spooling is. 3.在早期计算机中，每个字节的读写直接由CPU处理（即没有DMA）。对于多道程序设计而言这种组织方式有什么含义？ The prime reason for multiprogramming is to give the CPU something to do while waiting for I/O to complete. If there is no DMA, the CPU is fully occupied doing I/O, so there is nothing to be gained (at least in terms of CPU utilization) by multiprogramming. No matter how much I/O a program does, the CPU will be 100% busy. This is of course assume the major delay is the wait while data are copied. A CPU could do other work if the I/O were slow for other reasons (arriving on serial line, for instance). 4.系列计算机的思想在20世纪60年代由IBM引入进System/360大型机。现在这种思想已经消亡还是继续活跃着？ It is still alive. For example, Intel makes Pentium I, II, and III, and 4 CPUs with a variety of different properites including spped and power consumption. All of these machines ar architecturally compatible. They differ only in price and perfermance, which is the essence of the family idea. 5.缓慢采用GUI的一个原因是支持它的硬件的成本（高昂）。为了支持25行80列字符的单色文本屏幕应该需要多少视频RAM？对于1024x768像素24位色彩位图需要多少视频RAM？在1989年（$5/KB）这些RAM的成本是多少？现在它的成本是多少？ A 25x80 character monochrome text screen requires a 2000-byte buffer. 2580=2000 The 1024x768 pixel 24-bit color bitmap requires 2359296 bytes. 102476824/8=2359296 In 1980 these two options would have cost $10 and $11520, respectively. 20005/1024=9.77 2359296*5/1024=11520 For current prices, check on how much RAM currently costs, probably less than $1/MB. 6.在建立一个操作系统时有几个设计目的，例如资源利用、及时性，健壮性等。请列举两个可能互相矛盾的设计目的。 Consider fairness and real time. Fairness requires that each process be allocated it resources in a fair way, with no process getting more than its fair share. On the other hand, real time requires that resources be allocated based on the times when different processes must complete their execution. A real time process may get a disproportionate share of the resources. 7.下面哪一条指令只能在内核态中使用？ a)禁止所有的中断。 b)读日期-时间时钟。 c)设置日期-时间时钟。 d)改变存储器映像。 acd 8.考虑一个有两个CPU的系统，并且每一个CPU有两个线程（超线程）。假设有三个程序P0,P1,P2，分别以运行时间5ms,10ms,20ms开始。运行这些程序需要多少时间？假设这三个程序都是100%限于CPU，在运行时无阻塞，并且一旦设定就不改变CPU。 It may take 20, 25, 30 or 35 msec to complete the execution of these programs depending on how the operating system schedules them. If P0 and P1 are scheduled on the same CPU and P2 is scheduled on the other CPU, it will take 20 mses. If P0 and P2 are scheduled on the same CPU and P1 is scheduled on the other CPU, it will take 25 msec. If P1 and P2 are scheduled on the same CPU and P0 is scheduled on the other CPU, it will take 30 msec. If all three are on the same CPU, it will take 35 msec. 9.一台计算机有一个四级流水线，每一级都花费相同的时间执行其工作，即1ns。这台机器每秒可执行多少条指令？ Every nanosecond one instruction emerges from the pipeline. This means the machine is executing 1 billion instructions per second. It does not matter at all how many stages the pipeline has. A 10-stage pipeline with 1 nsec per stage would also execute 1 billion instructions per second. All that matters is how often a finished instruction pops out the end of the pipeline. 10.假设一个计算机系统有高速缓存、内存（RAM）以及磁盘，操作系统用虚拟内存。读取缓存中的一个词需要2ns，RAM需要10ns，磁盘需要10ms。如果缓存的命中率是95%，内存的是（缓存失效）99%，读取一个词的平均时间是多少？ Average access time = 0.95 × 2 nsec (word is cache) 0.05 × 0.99 × 10 nsec (word is in RAM, but not in cache) 0.05 × 0.01 × 10,000,000 nsec (word on disk only) = 5002.395 nsec = 5.002395 μsec 11.一位校对人员注意到在一部将要出版的操作系统教科书手稿中有一个多次出现的拼写错误。这本书大致有700页。每页50行，一行80个字符。若把文稿用电子扫描，那么，主副本进入图1-9中的每个存储系统的层次要花费多少时间？对于内存储方式，考虑所给定的存取时间是每次一个1024字符的盘块，而对于磁带，假设给定开始时间后的存取时间和和磁盘存储时间相同。 The manuscript contains 80 X 50 X 700 = 2.8 million characters. This is, of course, impossible to fit into the registers of any currently available CPU and is too big for a 1-MB cache, but if such hardware were available, the manuscript could be scanned in 2.8 msec ( 2.8 X 10^6 X 10^-9 s) from the registers or 5.8 msec (2.8 X 10^6 X 2 X 10^-9 s) from the cache. There are approximately 2700 ( 2.8 X 10^6 % 1024 = 2735 ) 1024-byte blocks of data, so scanning from the disk would require about 27 seconds (2700 X 10 X 10^-3= 27s ), and from tape 2 minutes 7 senconds ( 100 + 27 = 127s tape不考虑读入时的文件大小？ ). 12.**在用户程序进行一个系统调用，以读写磁盘文件时，该程序提供指示说明了所需要的文件，一个指向数据缓冲区的指针以及计数。然后，控制权转给操作系统，它调用相关的驱动程序。假设驱动程序启动磁盘并且直到中断发生才终止。在从磁盘读的情况下，很明显，调用者会被阻塞（因为文件中没有数据）。在向磁盘写时会发生什么情况？需要把调用者阻塞一直等到磁盘传送完成为止吗？ Maybe. If the caller get control back and immediately overwrites the data, when the write finally occurs, the wrong data will be written. However, if the driver first copied the data to a private buffer before returning, then the caller can be allowed to continue immediately. Another possiblity is to allow the caller to continue and give it a singal when the buffer may be used, but this is tricky and error prone. 13.什么是陷阱指令？在操作系统中解释它的用途。 A trap instruction switches the execution mode of a CPU from the user mode to the kernel mode. This instruction allow a user program to invoke functions in the operation system kernel. 14.陷阱和中断的主要差别是什么？ A trap is caused by the program and is synchronous with it. If the program is run again and again, the trap will always occur exactly the same position in the instruction stream. An interrupt is caused by an external event and its timing is not reproducible. 15.在分时系统中为什么需要进程表？在只有一个进程存在的个人计算机系统中，该进程控制整个机器直到进程结束，这种机器也需要进程表吗？ The process table is needed to store the state of a process that is currently suspended, either ready or blocked. It is not needed in a single process system because the single process is never suspended. 16.说明有没有理由要在一个非空的目录中安装一个文件系统？如果要这样做，如何做？ Mounting a file system makes any files already in the mount point directory inaccessible, so mount points are normally empty. However, a system administrator might want to copy some of the most important files normally located in the mounted directory to the mount point so they could be found in their noraml path in an emergency when the mounted device was being repaired. 17.在一个操作系统中系统调用的目的是什么？ A system call allows a user process to access and execute operating system functions indside the kernel. User programs use system calls to invoke operating system services. 18.对于下列系统调用，给出引起失败的条件：fork、exec以及unlink。 Fork can fail if there are no free slot left in the process table (and possibley if there is no memory or swap space left). Exec can fail if the file name given does not exist or is not a valid executable file. Unlink can fail if the file to be unlinked does not exist or the calling process does not have authority to unlink it. 19.在count = write(fd, buffer, nbytes);调用中，能在count中而不是nbytes中返回值吗？如果能，为什么？ If the call fails, for example because fd is incorrect, it can return -1. It can also fail because the disk is full and it is not possible to write the number of bytes requested. On a correct termination, it always return nbytes. 20.有一个文件，其文件描述符是fd，内含字节序列：3,1,4,1,5,9,2,6,5,3,5。有如下系统调用：lseek(fd,3,SEEK_SET); read(fd,&amp;buffter,4); 其中lseek调用寻找文件中的字节3。在读操作完成后，buffer中的内容是什么？ It contains the bytes: 1, 5, 9, 2. 21.假设一个10MB的文件存在磁盘连续扇区的同一个轨道上（轨道号：50）。磁盘的磁头臂此时位于第100号轨道。要想从磁盘上找回这个文件，需要多长时间？假设碰头臂从一个柱面移动到下一个柱面需要1ms，当文件的开始部分存储在的扇区旋转到磁头下需要5ms，并且读的速率是100MB/s。 (100-50)*1ms+5ms+10MB/100MB/s=55ms+0.1X10^3ms=155ms Time to retrieve the file = 1 * 50 ms (Time to move the arm over track # 50) 5 ms (Time for the first sector to rotate under the head) 10/100 * 1000 ms (Read 10 MB) = 155 ms 22.块特殊文件和字符特殊文件的基本差别是什么？ Block special files consist of numbered blocks, each of which can be read or written independently of all the other ones. It is possible to seek to any block and start reading and writing. This is not possible with character specical files. 23.在图1-17的例子中库调用称为read，而系统调用自身称为read。这两者都有相同的名字是正常的吗？如果不是，哪一个更重要？ System calls do not really have names, other than in a documentation sence. When the libray procedure read traps to the kernel, it puts the number of the system call in a register ro on the stack. This number is used to index into a table. There is really no name used anywhere. On the other hand, the name of the library procedure is very import, since this is what appears in the program. 24.在分布式系统中，客户机-服务器模式很普遍。这种模式能用在单个计算机的系统中吗？ Yes it can, especially if the kernel is message-passing system. 25.对于程序员而言，系统调用就像对其他库过程的调用一样。有无必要让程序员了解哪一个库过程导致了系统调用？在什么情形下，为什么？ As far as program logic is concerned it does not matter whether a call to a library procedure results in a system call. But if perfermance is an issue, if a task can be accomplished without a system call the program will run faster. Every system call involves overhead time in switching from the user context to the kernel context. Furthermore, on a multiuser system the operatiing system may schedule another process o run when a system call completes, further slowing the progress in real time of a calling process. 26.图1-23说明有一批UNIX的系统调用没有与之相等价的Win32 API。对于所列出的每一个没有Win32等价的调用，若程序员要把一个UNIX程序转换到Windows下运行，会有什么后果？ Serval UNIX calls have no counterpart in the Win32 API: Link: a Win32 program cannot refer to a file by an alternative name or see it in more than one directory. Also, attempting to create a link is a convenient way to test fro and create a lock on a file. Mount and umount: a Windows program cannot make assumptions about standard path names because on systems with multiple disk drives the drive name part of the path may be different. Chmod: Windows uses access control lists Kill: Windows programmers cannot kill a misbehaving program that is not cooperating. 27.可移植的操作系统是能从一个系统体系结构到另一个体系结构的移动不需要任何修改的操作系统。请解释为什么建立一个完全可移植性的操作系统是不可行的。描述一下在设计一个高度可移植的操作系统时你设计的高级的两层是什么样的。 Every system architecture has its own set of instructions that it can execute. Thus a Pentumn cannot excute SPARC programs and SPARC cannot execute Pentium programs. Also, different architectures differ in bus architecture used (such as VME, ISA, PCI, MCA, SBus, ..) as well as the word size of the CPU (usually 32 or 64 bit). Because of these differences in hardware, it is not feasible to build an operating system that is completely portable. A highly portable operating system will consist of two high-level layers—a machine-dependent layer and a machine independent layer. The machine-dependent layer addresses the specifics of the hardware, and must be implemented separately for every architecture. This layer provides a uniform interface on which the machine-independent layer is built. The machine-independent layer has to be implemented only onece. To be highly protable, the size of the machine-dependent layer must be kept as small as possible. 28.请解释在建立基于微内核的操作系统时策略与机制的分离带来的好处。 Separation of policy and mechanism allows OS designers to implement a small number of basic primitives in the kernel. These primitives are simpified, because they are not dependent of any specific policy. They can then be used to implement more complex mechanisms and policies at the user level. 29.下面是单位转换的练习： a)一微年是多少秒？ b)微米常称为micron。那么gigamicron是多长？ c)1TB存储器有多少字节？ d)地球的质量是6000yottagram，换算成kilogram是多少？ answers: a) A micro year is 10^-6 X 365 X 24 X 3600 = 31.536 sec. b) 10^9*10^-6=1000m c) 2^10 X 2^10 X 2^10 X 2^10 = 2^40 Bytes d) 6000 X 10^24 X 10^-3 = 6 X 10^24 kilogram 30.写一个各图1-19类似的shell，但是包含足够的实际可工作的代码，这样读者可以测试它。读者还可以添加某些功能，如输入输出重定向、管道以及后台作业等。 31.如果读者拥有一个个人UNIX类操作系统（Linux/MINIX/FreeBSD等），可以安全地崩溃和再启动，请写一个可以试图创建一个无限制数量子进程的shell脚本并观察所发生的事。在运行实验之前 ，通过shell键入sync，在磁盘上备份好文件缓冲区以避免毁坏文件系统。（注意：在没有得到系统管理呐的允许之前，不要在分时系统上进行这一尝试。其后果将会立即发生，尝试者可能会被抓住并受到惩罚。） 32.用一个类似于UNIX od或MS-DOS DEBUG的程序考察并尝试解释UNIX类系统或Windows的目录。提示：如何进行取决于OS允许做什么。一个有益的技巧是在一个有某个操作系统的软盘上创建一个目录，然后使用一个允许进行此类的访问的不同的操作系统读盘上的原始数据。]]></content>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 数据管理]]></title>
    <url>%2F2018%2F09%2F15%2Fdocker-data-management%2F</url>
    <content type="text"><![CDATA[Docker 提供了3种方式将数据从Docker宿主机挂载到容器： Volumes Bind mounts tmpfs mounts 一般来说，volumes总是最好的选择。 容器写入层的缺点我们可以将数据写到容器的可写入层，但是这种写入是有缺点的： 当容器停止运行时，写入的数据会丢失。你也很难将这些数据从容器中取出来给另外的应用程序使用。 容器的可写入层与宿主机是紧密耦合的。这些写入的数据在可以轻易地被删掉。 写入容器的可写入层需要一个存储驱动（storage driver）来管理文件系统。这个存储驱动通过linux内核提供了一个union filesystem。相比于数据卷（data volume），这种额外的抽象会降低性能。 选择合适的挂载方式不管你选择哪种挂载方式，从容器中看都是一样的。数据在容器的文件系统中被展示为一个目录或者一个单独的文件。 一个简单区分 volumes，bind mounts 和 tmpfs mounts 不同点的方法是：思考数据在宿主机上是如何存在的。 Volumes 由 Docker 管理，存储在宿主机的某个地方（在 linux 上是 /var/lib/docker/volumes/）。非 Docker 应用程序不能改动这一位置的数据。Volumes 是 Docker 最好的数据持久化方法。 Volumes 由 Docker 创建和管理。你可以通过 docker volume create 命令显式地创建 volume，Docker 也可以在创建容器或服务是自己创建 volume。 当你创建了一个 volume，它会被存放在宿主机的一个目录下。当你将这个 volume 挂载到某个容器时，这个目录就是挂载到容器的东西。这一点和 bind mounts 类似，除了 volumes 是由 Docker 创建的，和宿主机的核心（core functionality）隔离。 一个 volume 可以同时被挂载到几个容器中。即使没有正在运行的容器使用这个 volume，volume 依然存在，不会被自动清除。可以通过 docker volume prune 清除不再使用的 volumes。 volumes 也支持 volume driver，可以将数据存放在另外的机器或者云上。 Bind mounts 的数据可以存放在宿主机的任何地方。数据甚至可以是重要的系统文件或目录。非 Docker 应用程序可以改变这些数据。 Docker 早期就支持这个特性。与 volumes 相比，Bind mounts 支持的功能有限。使用 bind mounts 时，宿主机上的一个文件或目录被挂载到容器上。 警告：使用 Bind mounts 的一个副作用是，容器中运行的程序可以修改宿主机的文件系统，包括创建，修改，删除重要的系统文件或目录。这个功能可能会有安全问题。 tmpfs mounts 的数据只存储在宿主机的内存中，不会写入到宿主机的文件系统。 tmpfs mounts 的数据不会落盘。在容器的生命周期内，它可以被用来存储一些不需要持久化的状态或敏感数据。例如，swarm 服务通过 tmpfs mounts 来将 secrets 挂载到一个服务的容器中去。 适合Volumes的场景 在不同的容器中共享数据。 当 Docker 主机不能保证具有给定的目录或文件结构时，Volumes 可帮助你将 Docker 主机的配置与容器运行时分离。 当要将容器的数据存储在远程主机或云提供程序上的时候。 当你需要备份或迁移数据的时候。 适合bind mounts的场景 宿主机和容器共享配置文件。Docker 提供的 DNS 解决方案就是如此，将宿主机的 /etc/resolv.conf 挂载到每个容器中。 开发环境需要在宿主机和容器中共享代码。docker 的开发就是如此，毕竟容器中一般是没有编辑器的。 当 Docker 主机的文件或目录结构保证与容器所需的绑定装载一致时。 适合tmpfs mounts的场景 tmpfs mounts 主要用在你既不想在容器内，又不想在宿主机文件系统保存数据的时候。这可能是出于安全原因，也可能是你的应用需要写非常多的非持久化数据，tmpfs mounts 这时候可以保证容器性能。]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protocol Buffer Encoding]]></title>
    <url>%2F2018%2F06%2F03%2Fprotocol-buffer-encoding%2F</url>
    <content type="text"><![CDATA[本文翻译自： https://developers.google.com/protocol-buffers/docs/encoding 本文档介绍了 protocol buffer message 的二进制格式。你不需要知道这个就可以在你的应用程序中使用 protocol buffer，但如果你想了解 protocol buffer 格式对编码后的 message 大小的影响，该文档非常有用。 一个简单的 Message假设你有如下这个非常简单的 message 定义： message Test1 &#123; optional int32 a = 1;&#125; 在应用程序中，你创建了一个 Test1 message 并将 a 设置为 150，然后将 message 序列化为输出流。如果你能够检查编码后的 message，则会看到三个字节： 08 96 01 这些数字的含义是什么呢？我们将稍后展示。 Base 128 Varints要理解 protocol buffer 的编码，首先需要了解 varints。varints 是一种将整数序列化成一个或多个字节的方法。数字越小使用的字节数也越小。 varint 中的每个字节（最后一个字节除外）都设置了最高有效位（most significant bit），简称 msb，表示还有后续字节，如果只有单个字节则不设置 msb。每个字节的低7位用于以7位一组的形式存储数字的二进制补码，最低有效组放在前面。 例如，数字1，它是一个单字节，所以 msb 没有被设置： 0000 0001 如果是300，就有点复杂： 1010 1100 0000 0010 怎么知道这个是300的呢？首先从每个字节中删除 msb，因为 msb 只是告诉我们是否已达到数字的末尾。（如你所见，由于 varint 中有多个字节，所以 msb 被设置在第一个字节中）： 1010 1100 0000 0010 → 010 1100 000 0010 因为 varints 的最低有效组放在前面，所以需要反转两个7位组。最后进行拼接来获得实际的值： 000 0010 010 1100→ 000 0010 + 010 1100→ 100101100→ 256 + 32 + 8 + 4 = 300 Message 结构protocol buffer 的 message 是一系列 key-value 对。message 的二进制形式只使用了字段的编号作为 key，每个字段的名称和声明类型则是在解码端通过引用 message 类型的定义（即 .proto 文件）来确定的。 在对一个 message 进行编码时，key 和 value 被连接成一个字节流。当 message 被解码时，解析器需要跳过它无法识别的字段。这样，在 message 中添加新字段后也不会影响到旧程序。为此，每个 key 实际上由两个值组成： .proto 文件中的字段编号。 用来获取 value 长度信息的 wire 类型。 可用的 wire 类型如下： Type Meaning Used For 0 Varint int32, int64, uint32, uint64, sint32, sint64, bool, enum 1 64-bit fixed64, sfixed64, double 2 Length-delimited string, bytes, embedded messages, packed repeated fields 3 Start group groups (deprecated) 4 End group groups (deprecated) 5 32-bit fixed32, sfixed32, float 在流式 message 中的每个 key 都是一个值为 (field_number &lt;&lt; 3) | wire_type 的 varint。换句话说，数字的最后三位存储了 wire 类型。 现在让我们回过来看看之前那个简单的例子。你现在已经知道流中的第一个数字总是一个值为 varint 的 key，例子中 key 为 08（删除 msb）： 000 1000 取最后三位得到 wire 类型（0），然后右移三位得到字段编号（1）。所以字段编号是1，值是一个 varint。结合前面讲到的 varint 解码知识，可以看到接下来的两个字节存储的值为150。 96 01 = 1001 0110 0000 0001 → 000 0001 + 001 0110 (drop the msb and reverse the groups of 7 bits) → 10010110 → 128 + 16 + 4 + 2 = 150 更多的 value 类型有符号整型（Signed Integers）正如你在前面的章节中看到的那样，与 wire 类型0相关的所有 protocol buffer 类型都被编码为 varints。但是，在编码负数时，有符号的 int 类型（sint32 和 sint64）与“标准” int 类型（int32 和 int64）之间存在很大差异。如果使用 int32 或 int64 作为负数的类型，则生成的 varint 长度总是为10个字节 - 实际上，它被视为非常大的无符号整数；如果使用 sint32 或 sint64，对应的 varint 则会使用 ZigZag 编码，所以效率更高。 ZigZag 编码将有符号整数映射为无符号整数，因此绝对值小的数字（例如-1）就会有一个小的 varint 编码值。ZigZag 以一种在正整数和负整数之间来回“zig-zags”的方式来实现，所以-1被编码为1，1被编码为2，-2被编码为3，依此类推，如下表所示： Signed Original Encoded As 0 0 -1 1 1 2 -2 3 2147483647 4294967294 -2147483648 4294967295 换句话说，每个 sint32 类型的值 n 被编码为： (n &lt;&lt; 1) ^ (n &gt;&gt; 31) 每个 sint64 类型的值 n 被编码为： (n &lt;&lt; 1) ^ (n &gt;&gt; 63) 注意第二个移位操作 n &gt;&gt; 31 是一个算术移位。所以，这个移位操作的值要么所有位都是0（如果 n 是正数），要么所有位都为1（如果 n 是负数）。 在解析 sint32 或 sint64 时，其值按上述过程的逆操作解码回原来的有符号数。 非 varint 数字（Non-varint Numbers）非 varint 数字类型很简单，double 和 fixed64 的 wire 类型为1，它告诉解析器提取一块64位的数据；类似的， float 和 fixed32 的 wire 类型为5，它告诉解析器提取一块32位的数据。在这两种情况下，值都以小端字节顺序存储。 字符串（Strings）wire 类型 2 （length-delimited）表示该值是 varint 编码的长度，后面跟着指定的数据字节数。 例如有下面这样的 message 类型： message Test2 &#123; optional string b = 2;&#125; 将 b 的值设置为“testing”，会得到： 12 07 74 65 73 74 69 6e 67 红色的字节部分是 UTF8 编码的“testing”。这里的 key 是 0x12，可以得到字段编号为2，wire 类型为2。07 表示 value 的长度为7，随后的7个字节就是我们的字符串。 嵌套的 Message（Embedded Messages）下面是一个带有我们示例类型 Test1 的嵌入式 message 的定义： message Test3 &#123; optional Test1 c = 3;&#125; 下面是编码后的结果，Test1 的字段 a 设置为150： 1a 03 08 96 01 可以看到，最后三个字节与我们前面的第一个例子（08 96 01）完全相同，在它们前面是数字3。嵌入式 message 的处理方式与字符串完全相同（wire type = 2）。 可选和重复的元素（Optional And Repeated Elements）如果在 proto2 的 message 定义中有 repeated 的元素（没有[packed = true]选项），编码后的 message 会有零个或多个具有相同字段编号的 key-value 对。这些 repeated 的值不需要连续的出现，它们可能与其他的字段交错出现。解析时，这些元素相互之间的顺序会保存下来，但是相对于其他字段的顺序将会丢失。而 proto3 会利用打包编码（packed encoding）的方式对 repeated 字段进行编码，之后会介绍。 对于 proto3 中的任何非 repeated 字段或 proto2 中的 optional 字段，编码后的 message 可能有也可能没有该字段编号的 key-value 对。 通常，编码后的 message 永远不会有非 repeated 字段的多个实例。但是，解析器被设计为可以处理这种情况。对于数字类型和字符串，如果同一个字段出现多次，解析器将接受它看到的最后一个值。对于嵌套的 message 字段，解析器合并相同字段的多个实例，就像使用 Message::MergeFrom 方法一样 - 那就是，后面的实例的单个字段会替换掉前面出现的，单个嵌套 message 被合并，重复字段被连接起来。这些规则的效果是，解析串联出现的两个编码的 message 产生的结果和单独解析两个 message 然后合并它们的结果是相同的。示例如下： MyMessage message;message.ParseFromString(str1 + str2); 等同于： MyMessage message, message2;message.ParseFromString(str1);message2.ParseFromString(str2);message.MergeFrom(message2); 这个特性有的时候挺有用的，我们可以在不知道两个 message 的具体类型的情况下合并它们。 打包重复字段（Packed Repeated Fields）protocol buffer 在 2.1.0 版本引入了 packed repeated 字段，这个字段在 proto2 中的声明需要在 repeated 字段后面添加 [packed=true]。在 proto3 中，repeated 字段默认为 packed repeated 字段。这个字段和普通的 repeated 字段的区别在于编码方式不同。一个包含0个元素的 packed repeated 字段不会出现在编码后的 message 中。否则，该字段的所有元素都将打包到一个 wire 类型为2（length-delimited）的 key-value 对中。除了前面没有 key 以外，每个元素的编码方式与通常情况下相同。 假设你有如下的 message 类型： message Test4 &#123; repeated int32 d = 4 [packed=true];&#125; 现在构造一个 Test4，repeated 字段 d 的值有3、270和86942。编码后的结果如下： 22 // key (field number 4, wire type 2)06 // payload size (6 bytes)03 // first element (varint 3)8E 02 // second element (varint 270)9E A7 05 // third element (varint 86942) 只有原始数字类型（varint，32-bit 或 64-bit）的 repeated 字段才可以声明为“packed”。 请注意，虽然通常没有理由为 packed repeated 字段对多个 key-value 对进行编码，但编码器必须准备好接受多个 key-value 对。在这种情况下，payloads 应该被连接在一起。每一对都必须包含所有元素。 protocol buffer 解析器必须能够解析被编译为 packed 的 repeated 字段，就像它们未被打包一样，反之亦然。这就保证了 [packed=true] 选项的前后向兼容性。 字段顺序（Field Order）你可以在一个 .proto 文件中以任意顺序使用字段编号，当 message 被序列化时，已知的字段会按照字段编号顺序写入，可以参考提供的 C++，Java 和 Python 的序列化代码。这允许解析代码依赖于字段编号进行优化。但是，protocol buffer 解析器必须能够以任意顺序解析字段，因为并非所有 message 都是通过简单地序列化对象来创建的。例如，有时我们会通过一个简单的连接来合并两个 message。 如果 message 具有未知字段，则当前的 Java 和 C++ 实现在按顺序排序的已知字段之后以任意顺序写入它们，当前的 Python 实现则不会跟踪未知字段。]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Protocol Buffer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protocol Buffer 介绍]]></title>
    <url>%2F2018%2F06%2F02%2Fprotocol-buffer-introduction%2F</url>
    <content type="text"><![CDATA[protocol buffer 是一种语言无关，平台无关，可扩展的序列化结构化数据的方式，用于通信协议，数据存储等。 protocol buffer 目前支持Java，Python，Objective-C 和 C++ 中的生成代码。使用新的 proto3 语言版本，您还可以使用 Go，Ruby 和 C＃ 等更多语言。 为什么选择 Protocol Buffer ？通常我们定义好的请求和响应在客户端和服务端都需要手动编码/解码，但是随着接口的版本变化，可能需要对版本号进行判断才能做相应的处理。这样使得新的协议变得复杂，因为开发者必须确保请求发起者与处理请求的实际服务器之间的所有服务器都能理解新协议，然后才能开始使用新协议。 protocol buffer 旨在解决这些问题： 可以很容易地引入新的字段，中间服务器可以简单地解析并传递数据，而无需了解所有字段。 协议格式的描述性更强，可以用各种语言来处理（C ++，Java等），并且速度更快，空间更小。 开始使用开始使用 protocol buffer 的第一步，就是创建一个 .proto 文件来定义 protocol buffer 消息类型，指定你想要序列化的信息结构。 每个 protocol buffer 消息是一个小的逻辑信息记录，包含一系列 name-value 对。下面是 .proto 文件的一个例子，定义了一条包含人员信息的消息： message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; required string number = 1; optional PhoneType type = 2 [default = HOME]; &#125; repeated PhoneNumber phone = 4;&#125; 正如你所看到的，消息格式很简单。每种消息类型（如 message Person）都有一个或多个带有唯一编号的字段，每个字段都有一个名称和一个值类型。其中值类型可以是数字（整数或浮点数），布尔值，字符串，原始字节，甚至可以是其他 protocol buffer 的消息类型。在消息类型中，你可以指定可选字段，必填字段和重复字段。访问 Protocol Buffer Language Guide 以获取更多有关 .proto 文件的信息。 当在 .proto 文件中定义完消息后，你需要运行 protocol buffer 编译器为你使用的编程语言生成数据访问类。这为每个字段提供了简单的访问器（如 name() 和 set_name()），以及对整个结构的进行序列化/解析的方法。例如，如果您选择的语言是 C++，那么在上面的示例中运行编译器将生成一个名为 Person 的类。然后，就可以在应用程序中使用此类来填充，序列化并检索 Person protocol buffer 消息。你可能会写下如下代码： Person person;person.set_name("John Doe");person.set_id(1234);person.set_email("jdoe@example.com");fstream output("myfile", ios::out | ios::binary);person.SerializeToOstream(&amp;output); 然后，可以通过以下方式读取消息： fstream input("myfile", ios::in | ios::binary);Person person;person.ParseFromIstream(&amp;input);cout &lt;&lt; "Name: " &lt;&lt; person.name() &lt;&lt; endl;cout &lt;&lt; "E-mail: " &lt;&lt; person.email() &lt;&lt; endl; 你可以将新字段添加到消息格式中，而不会破坏向后兼容性; 解析时旧的二进制文件会简单地忽略新字段。所以如果你有一个使用 protocol buffer 作为数据格式的通信协议，你可以扩展你的协议，而不用担心破坏现有的代码。 详细的 protocol buffer 介绍以及使用请参考 官方文档。]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Protocol Buffer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序 - 便利店在哪（已上线）]]></title>
    <url>%2F2018%2F02%2F27%2Fweapp-store%2F</url>
    <content type="text"><![CDATA[业余时间做了一个小程序 “便利店在哪”，功能很简单，就是找出你附近的便利店。 灵感来源于经常找不到地方买烟。。。 代码已经开源在 Github 上了，地址：royeo/weapp-store ，欢迎 star。]]></content>
      <categories>
        <category>与日俱新</category>
      </categories>
      <tags>
        <tag>微信小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node 循环依赖之源码解析]]></title>
    <url>%2F2018%2F01%2F29%2Fnode-circular-dependency%2F</url>
    <content type="text"><![CDATA[今天来讲一讲 Node 循环依赖的问题，以官网上的例子结合 Node 源码来分析为什么循环依赖不会导致死循环，以及循环依赖可能造成的问题。 什么是循环依赖循环依赖是两个或多个模块之间的关系，它们直接或间接地相互依赖以正常运行。 循环依赖的案例官网上给出的例子是这样的： a.js: console.log('a starting');exports.done = false;const b = require('./b.js');console.log('in a, b.done = %j', b.done);exports.done = true;console.log('a done'); b.js: console.log('b starting');exports.done = false;const a = require('./a.js');console.log('in b, a.done = %j', a.done);exports.done = true;console.log('b done'); main.js: console.log('main starting');const a = require('./a.js');const b = require('./b.js');console.log('in main, a.done=%j, b.done=%j', a.done, b.done); 官网的解释是： main.js 先加载 a.js，然后 a.js 中会加载 b.js，但是在 b.js 中又加载了 a.js。这个时候为了防止无限循环，会将a.js 未完成的 exports 对象返回给 b.js 模块，接着 b.js 完成加载，并且它的 exports 对象被提供给 a.js 模块。 由此可以看出，之所以不会发生依赖的死循环，是因为模块能够导出未完成的 exports 对象。那么问题来了，为什么模块没有执行完，却能导出对象呢？ 下面通过分析模块源码 lib/module.js 来解答这个问题。要注意的是，核心模块和文件模块（用户编写的模块）的加载是不同的，本文只讨论文件模块的加载。为了便于理解，会对源码进行简化。 Module 构造函数在 Node 中，每个模块在被 require 导入的时候都会创建一个模块实例，即 Module 实例，并且 Node 会缓存每个模块的实例，以便在下次 require 该模块的时候可以直接从缓存中返回。 模块实例有一个 exports 属性，初始化为空对象。当我们在文件模块中通过 module.exports 或 exports 来导出的时候，其实就是在给模块实例的 exports 添加属性或者直接重写它。 // Module 构造函数function Module(id, parent) &#123; this.id = id; this.exports = &#123;&#125;; this.parent = parent; updateChildren(parent, this, false); this.filename = null; this.loaded = false; this.children = [];&#125; require 方法require 方法定义在 Module 的原型链上，被每个模块实例共享。 Module.prototype.require = function(id) &#123; return Module._load(id, this, false);&#125;; require 内部调用 Module._load 方法，下面是简化后的 _load 方法。 Module._load = function(request, parent, isMain) &#123; // 获取模块文件的绝对路径 var filename = Module._resolveFilename(request, parent, isMain); // 如果有缓存，直接返回缓存中的模块实例的 exports 属性 var cachedModule = Module._cache[filename]; if (cachedModule) &#123; return cachedModule.exports; &#125; // 如果是核心模块，使用 NativeModule.require 方法加载 if (NativeModule.nonInternalExists(filename)) &#123; return NativeModule.require(filename); &#125; // 创建模块实例，并存入缓存 var module = new Module(filename, parent); Module._cache[filename] = module; // 加载模块 module.load(filename); return module.exports;&#125;; 上面的代码中，以模块的绝对路径作为模块id，优先从缓存中获取模块实例的 exports 属性。如果模块实例不在缓存中，则创建模块实例并存入缓存，最后根据模块id调用 module.load 加载该模块。 加载模块模块的加载通过 module.load 方法完成，该方法根据模块的绝对路径确定文件扩展名，不同的文件扩展名采用不同的加载方法。 Module.prototype.load = function(filename) &#123; this.filename = filename; this.paths = Module._nodeModulePaths(path.dirname(filename)); var extension = path.extname(filename) || '.js'; if (!Module._extensions[extension]) extension = '.js'; Module._extensions[extension](this, filename); this.loaded = true;&#125;; 以 .js 扩展名为例，处理方法如下： Module._extensions['.js'] = function(module, filename) &#123; var content = fs.readFileSync(filename, 'utf8'); module._compile(internalModule.stripBOM(content), filename);&#125;; module._compile 方法对模块文件进行编译执行。 Module.prototype._compile = function(content, filename) &#123; // 将模块代码包装在一个函数中 var wrapper = Module.wrap(content); // 在当前全局上下文中编译包装好的模块代码，并返回一个可执行的函数 var compiledWrapper = vm.runInThisContext(wrapper, &#123; ... &#125;); // 获取模块目录的路径 var dirname = path.dirname(filename); // 扩展 require 方法，如添加 require.resolve、require.cache 等属性 var require = internalModule.makeRequireFunction(this); // 传入模块实例的 exports 属性、require 方法、模块实例自身、完整文件路径 // 和文件目录来执行该函数。 var result = compiledWrapper.call(this.exports, this.exports, require, this, filename, dirname); return result;&#125;; Module.wrap = function(script) &#123; return Module.wrapper[0] + script + Module.wrapper[1];&#125;;Module.wrapper = [ '(function (exports, require, module, __filename, __dirname) &#123; ', '\n&#125;);']; vm.runInThisContext 这个方法会在 V8 虚拟机环境中编译代码，并在当前全局的上下文中运行代码并返回结果。在全局上下文运行的好处是在模块中我们可以使用一些全局变量，如：process、console 等。具体参考：vm 的官方文档。 上面的代码使用 Module.wrap 将模块代码包装在函数中，这样就避免了作用域被污染，接着通过执行 vm.runInThisContext 返回一个可执行的函数，最后传入当前模块实例的 exports 属性、模块实例的 this，以及require 方法、完整文件路径和文件目录来执行该函数。 由此也可以看出，module.exports 和 exports 并不是全局的，而是在执行模块代码的包装函数时传入的参数（当前模块实例的 exports）。这也解释了为什么在文件模块中重写 exports 会无法导出，因为它只能改变函数形参的引用，而无法实际影响到当前模块实例的 exports 属性。 循环依赖在分析完模块的整个加载过程后，回到上面那个问题：为什么模块没有执行完，却能导出对象呢？关键就在于，在加载模块时，如果模块没有缓存，会先创建模块实例，然后存入缓存，再编译执行模块代码。 以官网的例子来说： a.js 先加载，所以先缓存 a.js 的模块实例，然后编译执行 a.js。 在执行 a.js 的过程中，先导出 exports.done = false，此时 a.js 模块实例的 exports 属性值为 { done: false }。接着加载 b.js。 b.js 在执行过程中发现需要加载 a.js，此时由于 a.js 模块已经被缓存，所以直接获取到缓存中的 a.js 模块实例的 exports 属性，值为 { done: false }，然后继续执行。 b.js 执行完毕返回，a.js 继续执行。 这种循环依赖导致的问题很明显： b.js 在执行过程中获取到的 a.js 的导出可能是不完整的。 如果 a.js 在加载 b.js 后重写了 module.exports，b.js 中获取到的 a.js 的导出还是维持着旧的引用。 具体的解决方案可以参考 Maples7 的博客：Node.js 中的模块循环依赖及其解决。 References Modules | Node.js Documentation VM | Node.js Documentation node/lib/module.js - Github require() 源码解读 - 阮一峰 Node.js 中的循环依赖 - SegmentFault Node.js 中的模块循环依赖及其解决 - Maples7]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Node</tag>
        <tag>模块</tag>
        <tag>源码</tag>
        <tag>循环依赖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nodejs V8 的内存管理与垃圾回收机制]]></title>
    <url>%2F2018%2F01%2F10%2Fnode-v8%2F</url>
    <content type="text"><![CDATA[V8 的内存限制在 Node 中通过 javascirpt 只能使用部分内存（64位系统下约为1.4GB，32位系统下约为0.7GB），这个限制会导致 Node 无法直接操作大内存对象，计算机的内存资源无法得到充足的使用。 造成这个问题的主要原因在于 Node 基于 V8 构建，所以在 Node 中使用的 javascirpt 对象基本都是通过 V8 自己的方式进行分配和管理，V8 的这套内存管理机制在浏览器的应用场景下使用起来绰绰有余，但在 Node 中却限制了开发者随心所欲使用大内存的想法。还有一个深层原因是 V8 的垃圾回收机制的限制。官方说法，以1.5GB的垃圾回收堆内存为例，V8 做一次小的垃圾回收需要50毫秒以上，做一次非增量式的垃圾回收甚至要1秒以上。这是垃圾回收中引起JS线程暂停执行的时间，在这样时间花销下，应用的性能和响应能力都会直线下降。 在 V8 中，所有的 JS 对象都是通过堆来进行分配的。通过 process.memoryUsage() 命令可查看 V8 内存使用量： &#123; rss: 18702336, heapTotal: 10295296, # 已申请到的堆内存 heapUsed:5409936 # 当前使用量&#125; V8 依然提供了选项让我们使用更多的内存，Node 在启动时可以传递 --max-old-space-size 或 --max-new-space-size 来调整内存限制的大小，启动之后就无法改变了。例如： node --max-old-space-size=1700 app.jsnode --max-new-space-size=1024 app.js V8 的垃圾回收机制在 V8 中，主要将内存分为新生代和老生代。新生代中的对象为存活时间较短的对象，老生代中的对象为存活时间较长或常驻内存的对象。 新生代内存回收机制新生代的对象通过 Scavenge 算法进行垃圾回收，她将新生代的堆内存空间一分为二，每个空间称为 semispace，其中一个处于使用中（ From 空间），另一个处于闲置状态（ To 空间）。当我们分配对象时，先是从 From 空间进行分配，当开始进行垃圾回收时，会检查 From 空间中的存活对象，这些存活对象会被复制到 To 空间，而非存活对象占用的空间将会释放，也就是释放 From 空间。完成复制后，From 空间和 To 空间角色互换。简单来说，就是通过将存活对象在两个 semispace 空间之间进行复制。 在一定条件下，需要将存活周期长的对象移动到老生代中，也就是完成对象晋升。对象晋升的条件有两个，一个是对象是否经历过 Scavenge 回收，一个是 To 空间的内存占用比超过限制。 在对象从 From 空间复制到 To 空间时，会检查它的内存地址来判断这个对象是否已经经历过一次 Scavenge 回收，如果已经经历过，会将该对象从 From 空间复制到老生代空间中，如果没有，则复制到 To 空间中。 当从 From 空间复制一个对象到 To 空间时，如果 To 空间已经使用了超过25%，则这个对象直接晋升到老生代空间中。因为当这次 Scavenge 回收完成后，这个 To 空间将变成 From 空间，接下来的内存分配将在这个空间中进行，如果占比过高，会影响后续的内存分配。 Scavenge 的缺点是只能使用堆内存中的一半，这是由划分空间和复制机制所决定的。但 Scavenge 由于只复制存活的对象，并且对于生命周期短的场景存活对象只占少部分，所以它在时间效率上有优异的表现。由于 Scavenge 是典型的牺牲空间换取时间的算法，所以无法大规模地应用到所有的垃圾回收中。但可以发现，Scavenge 非常适合应用在新生代中，因为新生代中对象的生命周期较短，恰恰适合这个算法。 老生代内存回收机制对于老生代中的对象，由于存活对象占较大比重，再采用 Scavenge 的方式会有两个问题：一个是存活对象较多，复制存活对象的效率将会很低；另一个问题依然是浪费一半空间的问题。为此，V8 在老生代中主要采用 Mark-Sweep 和 Mark-Compack 相结合的方式进行垃圾回收。 Mark-Sweep Mark-Sweep 是标记清除的意思，它分为标记和清除两个阶段。与 Scavenge 复制活着的对象不同，Mark-Sweep 在标记阶段遍历堆中的所有对象，并标记活着的对象，在随后的清除阶段中，只清除没有被标记的对象。可以看出 Scavenge 只复制活着的对象，Mark-Sweep 只清除死亡对象。活对象在新生代中只占较小部分，死对象在老生代中只占较小部分，这是两种回收方式能高效处理的原因。 Mark-Compack Mark-Sweep 最大的问题是在进行一次标记清除后，内存空间会出现不连续的状态，这样内存碎片会对后续的内存分配造成问题，因为很可能出现需要分配一个大对象的情况，这时所有的碎片空间都无法完成此次分配，就会提前触发垃圾回收，而这次回收是不必要的。 为了解决 Mark-Sweep 的内存碎片问题，Mark-Compack 被提出来了。Mark-Compack 是标记整理的问题，是在 Mark-Sweep 的基础上演变而来的，它们的差别在于对象在标记为死亡后，在整理过程中，将活着的对象往一端移动，移动完成后，直接清理掉边界外的内存。 回收算法 Mark-Sweep Mark-Compact Scavenge 速度 中等 最慢 最快 空间开销 少（有碎片） 少（无碎片） 双倍空间（无碎片） 是否移动对象 否 是 是 从表格上看，Mark-Sweep 和 Mark-Compact 之间，由于 Mark-Compact 需要移动对象，所以它的执行速度不可能很快，所以在取舍上，V8 主要使用 Mark-Sweep，在空间不足以对从新生代中晋升过来的对象进行分配时才使用 Mark-Compact。 增量标记为了避免出现 js 应用逻辑与垃圾回收器看到的不一致的情况，垃圾回收的3种基本算法都需要将应用逻辑暂停下来，待执行完垃圾回收后再恢复执行应用逻辑，这种行为被称为“全停顿”（stop-the-world）。在 V8 的分代式垃圾回收中，一次小垃圾回收只收集新生代，由于新生代默认配置得较小，且其中存活对象通常较少，所以即便它是全停顿的影响也不大。但 V8 的老生代通常配置得较大，且存活对象较多，全堆垃圾回收（full垃圾回收）的标记、清理、整理等动作造成的停顿就会比较可怕，需要设法改善。 为了降低全堆垃圾回收带来的停顿时间，V8 先从标记阶段入手，将原本要一口气停顿完成的动作改为增量标记（incremental marking），也就是拆分为许多小“步进”，每做完一“步进”就让 js 应用逻辑执行一小会，垃圾回收与应用逻辑交替执行直到标记阶段完成。 V8 在经过增量标记的改进后，垃圾回收的最大停顿时间可以减少到原本的1/6左右。V8 后续还引入了延迟清理（lazy sweeping）与增量式整理（incremental compaction），让清理与整理动作也变成增量式的。同时还计划引入并行标记与并行清理，进一步利用多核性能降低每次停顿的时间。 小结从 V8 的自动垃圾回收机制的设计角度可以看到，V8 对内存使用进行限制的缘由。新生代设计为一个较小的内存空间是合理的，而老生代空间过大对于垃圾回收并无特别意义。V8对内存限制的设置对于 Chrome 浏览器这种每个选项卡页面使用一个 V8 实例而言，内存的使用是绰绰有余，对于 Node 编写的服务器端来说，内存限制也并不影响正常场景下的使用。但是对于V8的垃圾回收特点和 js 在单线程上的执行情况，垃圾回收是影响性能的因素之一。想要高性能执行效率，需要注意让垃圾回收尽量少地进行，尤其是全堆垃圾回收。]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读后感：《 一只特立独行的猪 》 — 王小波]]></title>
    <url>%2F2017%2F12%2F16%2Fa-maverick-pig%2F</url>
    <content type="text"><![CDATA[第一次看到这个书名《一只特立独行的猪》，我觉得很有意思，一只猪如何做到特立独行？带着这个问题我读了王小波的这本杂文。 猪给我的印象就是被圈养在又脏又臭的狭小环境中（此处自动忽略网易的味央猪…），吃了睡，睡了吃，直到它成为餐桌上的食物，被广罗大众花式烹饪。但其实很多人不知道，猪其实是很聪明的生物，甚至比狗和黑猩猩都聪明，而且它们很爱干净。但因为长期活在人类的“统治”之下，猪接受了这样的设置，过着“井井有条”的生活。 书中的一篇杂文讲述了作者与这只特立独行的猪的经历，那是一个趣味十足又耐人寻味的故事。故事中猪是一只非常有灵性的猪，有山羊般的敏捷，也有猫一样的灵活，活的竟然有些潇洒。它没有配合宿命的安排，而是选择了抗争，即使是在面对惨烈的杀猪现场也能镇定自若，机智逃脱，重新主宰了自己的命运。这里特别想引用一下《乔布斯传》里提到的一句广告语： 致疯狂的人。他们特立独行。他们桀骜不驯。他们惹是生非。他们格格不入。他们用与众不同的眼光看待事物。他们不喜欢墨守成规。他们也不愿安于现状。你可以认同他们，反对他们，颂扬或是诋毁他们。但唯独不能漠视他们。 动物也好，人类也好，生存是亘古不变的话题，生存之下则有不同的活法。王小波写这只猪的故事仿佛也是在写他自己，他自己的特立独行，他的自由主义理念，与“猪兄”都不谋而合。恰逢那时候刚看完电影“猩球崛起”，感觉电影里的凯撒和这只猪有很多相似之处，它们都在打破常规，对设置好的生活勇敢的 say “no”，自己掌控着自己命运的方向盘，不怕风越大浪越高。反而是我们自己，可能还不如它们 。。。 我已经四十岁了，除了这只猪，还没见过谁敢于如此无视对生活的设置。相反，我倒见过很多想要设置别人生活的人，还有对被设置的生活安之若素的人。因为这个缘故，我一直怀念这只特立独行的猪。 《 一只特立独行的猪 》王小波]]></content>
      <categories>
        <category>书海无涯</category>
      </categories>
      <tags>
        <tag>王小波</tag>
        <tag>一只特立独行的猪</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node.js 相关技术书籍推荐]]></title>
    <url>%2F2017%2F12%2F03%2Fbook-recommond%2F</url>
    <content type="text"><![CDATA[接触 Node.js 也有段时间了，从一开始对 Node.js 一无所知，到现在能在项目中熟练使用，书籍、文档和实战缺一不可。在学习初期，书籍扮演着一个非常重要的角色，让我对 Node.js 有了一个系统的认识。从看《JavaScript高级程序设计》开始，陆陆续续看了不少 JavaScript、Node.js 以及后端技术的相关书籍。书看的越多，会越发觉得自己知识匮乏，然后就会去寻找更多的书来充实自己。下面就是我整理的 Node.js 后端开发相关的经典技术书籍，排名不分先后，括号内是豆瓣评分，仅作参考。部分书籍的 pdf 文件可以到我的 Github 上去下载。 JavaScript 《JavaScript高级程序设计第三版》（9.3） 《你不知道的JavaScript》（9.4） 《JavaScript语言精粹》（9.1） 《JavaScript设计模式与开发实践》（9.2） 《JavaScript语言精髓与编程实践》（9.1） 《JavaScript面向对象精要》（9.0） 《JavaScript权威指南》（8.7） 《JavaScript函数式编程》（7.3） 《JavaScript设计模式》（8.4） 《JavaScript模式》（8.6） 《Effective JavaScript》（8.4） 《JavaScript忍者秘籍》（8.7） 《高性能JavaScript》（8.9） 《精通JavaScript》（8.6） Node.js 《Node.js实战》（8.4） 《深入浅出node.js》（8.7） 《The Node Beginner Book》（8.7） 《Node学习指南》（7.6） 《Node与Express开发》（7.5） 《Node.js开发指南》（7.5） 《Node.js权威指南》（7.3） 《Node即学即用》（7.3） MySql 《高性能MySQL（第3版）》（9.3） 《MySQL技术内幕：InnoDB存储引擎（第2版）》（8.6） 《深入浅出MySQL 数据库开发 优化与管理维护 第2版》（8.3） 《高可用MySQL（第2版）》（8.0） 《SQL基础教程（第3版）》（8.8） Redis 《Redis实战》（8.3） 《Redis设计与实现》（8.5） MongoDB 《MongoDB权威指南 第2版》（8.1） 《MongoDB应用设计模式》（6.1） HTTP 《HTTP权威指南》（8.7） 《Web性能权威指南》（8.8） 其他 《程序员修炼之道-从小工到大家》 《高效程序员的45个习惯 敏捷开发修炼之道》 《软件随想录》 《重构-改善既有代码的设计》 《代码简洁之道》 《高效团队开发的工具与方法》 《GitHub入门与实践》 《技术管理之巅》 《架构即未来》 《持续交付-发布可靠软件的系统方法》 《设计模式-可复用面向对象软件基础》 《设计模式之禅（第2版）》 《企业应用架构模式》 《领域驱动设计 软件核心复杂性应对之道》 《实现领域驱动设计》 《ZooKeeper：分布式过程协同技术详解》 《RabbitMQ实战：高效部署分布式消息队列》 《Redis设计与实现》 《实战Nginx：取代Apache的高性能Web服务器》 《大型网站技术架构 核心原理与案例分析》 《大型分布式网站架构设计与实践》 《微服务架构与实践》 《分布式服务框架原理与实践》]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Node.js</tag>
        <tag>技术书籍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读后感：《 沉默的大多数 》 — 王小波]]></title>
    <url>%2F2017%2F05%2F05%2Fmost-of-silence%2F</url>
    <content type="text"><![CDATA[初读王小波的书，觉得书中的故事大抵离当代社会有点距离。细细品来，方知个中思想在那个年代实属超前，妙言要道。书中很多文章读一遍，尚不能完全领会作者之深意，多次回顾与思辨，才感悟到其中的真知灼见，大有裨益，对于王小波的幽默与锐气也产生了由衷的赞赏。 语录话语教会我们很多，但善恶还是可以自明。话语想要教会我们，人与人生来就不平等。在人间，尊卑有序是永恒的真理，但你也可以不听。 一个人倘若需要从思想中得到快乐，那么他的第一个欲望就是学习。 知识虽然可以带来幸福，但假如把它压缩成药丸子灌下去，就丧失了乐趣。 正如上坡和下坡是一条路。 在科学上，有错误的学说，没有卑鄙的学说。 有些人受穷，是因为他不想富裕。 贫困是一种生活方式，富裕是另一种生活方式；追求聪明是一种人生的态度，追求愚蠢则是另一种生活态度。 吃苦必须有收益，牺牲必须有代价。 痛苦是艺术的源泉。 对残疾人的最大尊重，就是不把他当残疾人。 人生唯一的不幸就是自己的无能。]]></content>
      <categories>
        <category>书海无涯</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown 中文技术文档的写作规范]]></title>
    <url>%2F2017%2F01%2F20%2Fmarkdown-standard%2F</url>
    <content type="text"><![CDATA[本文转载自: https://github.com/ruanyf/document-style-guide 中文技术文档的写作规范。 标题层级标题分为四级。 一级标题：文章的标题 二级标题：文章主要部分的大标题 三级标题：二级标题下面一级的小标题 四级标题：三级标题下面某一方面的小标题 原则 一级标题下，不能直接出现三级标题。 标题要避免孤立编号（即同级标题只有一个）。 下级标题不重复上一级标题的内容。 谨慎使用四级标题，尽量避免出现，保持层级的简单和防止出现过于复杂的章节。如果三级标题下有并列性的内容，建议只使用项目列表（Item list）。 文本字间距全角中文字符与半角英文字符之间，应有一个半角空格。 错误：本文介绍如何快速启动Windows系统。正确：本文介绍如何快速启动 Windows 系统。 全角中文字符与半角阿拉伯数字之间，有没有半角空格都可，但必须保证风格统一，不能两种风格混杂。 正确：2011年5月15日，我订购了5台笔记本电脑与10台平板电脑。正确：2011 年 5 月 15 日，我订购了 5 台笔记本电脑与 10 台平板电脑。 半角的百分号，视同阿拉伯数字。 英文单位若不翻译，单位前的阿拉伯数字与单位间不留空格。 错误：一部容量为 16 GB 的智能手机正确：一部容量为 16GB 的智能手机 半角英文字符和半角阿拉伯数字，与全角标点符号之间不留空格。 错误：他的电脑是 MacBook Air 。正确：他的电脑是 MacBook Air。 句子 避免使用长句。一个句子建议不超过 100 字或者正文的 3 行。 尽量使用简单句和并列句，避免使用复合句。 写作风格尽量不使用被动语态，改为使用主动语态。 错误：假如此软件尚未被安装，正确：假如尚未安装这个软件， 不使用非正式的语言风格。 错误：Lady Gaga 的演唱会真是酷毙了，从没看过这么给力的表演！！！正确：无法参加本次活动，我深感遗憾。 用对“的”、“地”、“得”。 她露出了开心的笑容。（形容词＋的＋名词）她开心地笑了。（副词＋地＋动词）她笑得很开心。（动词＋得＋副词） 使用代词时（比如“其”、“该”、“此”、“这”等词），必须明确指代的内容，保证只有一个含义。 错误：从管理系统可以监视中继系统和受其直接控制的分配系统。正确：从管理系统可以监视两个系统：中继系统和受中继系统直接控制的分配系统。 名词前不要使用过多的形容词。 错误：此设备的使用必须在接受过本公司举办的正式的设备培训的技师的指导下进行。正确：此设备必须在技师的指导下使用，且指导技师必须接受过由本公司举办的正式设备培训。 单个句子的长度尽量保持在 20 个字以内；20～29 个字的句子，可以接受；30～39 个字的句子，语义必须明确，才能接受；多于 40 个字的句子，在任何情况下都不能接受。 错误：本产品适用于从由一台服务器进行动作控制的单一节点结构到由多台服务器进行动作控制的并行处理程序结构等多种体系结构。正确：本产品适用于多种体系结构。无论是由一台服务器（单一节点结构），还是由多台服务器（并行处理结构）进行动作控制，均可以使用本产品。 同样一个意思，尽量使用肯定句表达，不使用否定句表达。 错误：请确认没有接通装置的电源。正确：请确认装置的电源已关闭。 避免使用双重否定句。 错误：没有删除权限的用户，不能删除此文件。正确：用户必须拥有删除权限，才能删除此文件。 英文处理英文原文如果使用了复数形式，翻译成中文时，应该将其还原为单数形式。 英文：...information stored in random access memory (RAMs)...中文：……存储在随机存取存储器（RAM）里的信息…… 外文缩写可以使用半角圆点(.)表示缩写。 U.S.A.Apple, Inc. 表示中文时，英文省略号（...）应改为中文省略号（……）。 英文：5 minutes later...中文：5 分钟过去了…… 英文书名或电影名改用中文表达时，双引号应改为书名号。 英文：He published an article entitled &quot;The Future of the Aviation&quot;.中文：他发表了一篇名为《航空业的未来》的文章。 第一次出现英文词汇时，在括号中给出中文标注。此后再次出现时，直接使用英文缩写即可。 IOC（International Olympic Committee，国际奥林匹克委员会）。这样定义后，便可以直接使用“IOC”了。 专有名词中每个词第一个字母均应大写，非专有名词则不需要大写。 “American Association of Physicists in Medicine”（美国医学物理学家协会）是专有名词，需要大写。“online transaction processing”（在线事务处理）不是专有名词，不应大写。 段落原则 一个段落只能有一个主题，或一个中心句子。 段落的中心句子放在段首，对全段内容进行概述。后面陈述的句子为核心句服务。 一个段落的长度不能超过七行，最佳段落长度小于等于四行。 段落的句子语气要使用陈述和肯定语气，避免使用感叹语气。 段落之间使用一个空行隔开。 段落开头不要留出空白字符。 引用引用第三方内容时，应注明出处。 One man’s constant is another man’s variable. — Alan Perlis 如果是全篇转载，请在全文开头显著位置注明作者和出处，并链接至原文。 本文转载自 WikiQuote 使用外部图片时，必须在图片下方或文末标明来源。 本文部分图片来自 Wikipedia 数值半角数字数字一律使用半角形式，不得使用全角形式。 错误： 这件商品的价格是１０００元。正确： 这件商品的价格是 1000 元。 千分号数值为千位以上，应添加千分号（半角逗号）。 XXX 公司的实收资本为 RMB1,258,000。 对于 4 ～ 6 位的数值，千分号是选用的，比如1000和1,000都可以接受。对于7位及以上的数值，千分号是必须的。 多位小数要从小数点后从左向右添加千分号，比如4.234,345。 货币货币应为阿拉伯数字，并在数字前写出货币符号，或在数字后写出货币中文名称。 $1,0001,000 美元 数值范围表示数值范围时，用～连接。参见《标点符号》一节的“连接号”部分。 带有单位或百分号时，两个数字都要加上单位或百分号，不能只加后面一个。 错误：132～234kg正确：132kg～234kg错误：67～89%正确：67%～89% 变化程度的表示法数字的增加要使用“增加了”、“增加到”。“了”表示增量，“到”表示定量。 增加到过去的两倍（过去为一，现在为二）增加了两倍（过去为一，现在为三） 数字的减少要使用“降低了”、“降低到”。“了”表示增量，“到”表示定量。 降低到百分之八十（定额是一百，现在是八十）降低了百分之八十（原来是一百，现在是二十） 不能用“降低N倍”或“减少N倍”的表示法，要用“降低百分之几”或“减少百分之几”。因为减少（或降低）一倍表示数值原来为一百，现在等于零。 标点符号原则 中文语句的标点符号，均应该采取全角符号，这样可以保证视觉的一致。 如果整句为英文，则该句使用英文/半角标点。 句号、问号、叹号、逗号、顿号、分号和冒号不得出现在一行之首。 句号中文语句中的结尾处应该用全角句号（。）。 句子末尾用括号加注时，句号应在括号之外。 错误：关于文件的输出，请参照第 1.3 节（见第 26 页。）正确：关于文件的输出，请参照第 1.3 节（见第 26 页）。 逗号逗号，表示句子内部的一般性停顿。 注意避免“一逗到底”，即整个段落除了结尾，全部停顿都使用逗号。 顿号句子内部的并列词，应该用全角顿号(、) 分隔，而不用逗号，即使并列词是英语也是如此。 错误：我最欣赏的科技公司有 Google, Facebook, 腾讯, 阿里和百度等。正确：我最欣赏的科技公司有 Google、Facebook、腾讯、阿里和百度等。 英文句子中，并列词语之间使用半角逗号（,）分隔。 例句：Microsoft Office includes Word, Excel, PowerPoint, Outlook and other components. 分号分号；表示复句内部并列分句之间的停顿。 引号引用时，应该使用全角双引号（“ ”），注意前后双引号不同。 例句：许多人都认为客户服务的核心是“友好”和“专业”。 引号里面还要用引号时，外面一层用双引号，里面一层用单引号（‘ ’），注意前后单引号不同。 例句：鲍勃解释道：“我要放音乐，可萨利说，‘不行！’。” 圆括号补充说明时，使用全角圆括号（），括号前后不加空格。 例句：请确认所有的连接（电缆和接插件）均安装牢固。 冒号全角冒号（：）常用在需要解释的词语后边，引出解释和说明。 例句：请确认以下几项内容：时间、地点、活动名称，以及来宾数量。 表示时间时，应使用半角冒号（:）。 例句：早上 8:00 省略号省略号……表示语句未完、或者语气的不连续。它占两个汉字空间、包含六个省略点，不要使用。。。或...等非标准形式。 省略号不应与“等”这个词一起使用。 错误：我们为会餐准备了香蕉、苹果、梨…等各色水果。正确：我们为会餐准备了各色水果，有香蕉、苹果、梨……正确：我们为会餐准备了香蕉、苹果、梨等各色水果。 感叹号应该使用平静的语气叙述，尽量避免使用感叹号！。 不得多个感叹号连用，比如！！和!!!。 破折号破折号————一般用于做进一步解释。破折号应占两个汉字的位置。 例句：直觉————尽管它并不总是可靠的————告诉我，这事可能出了些问题。 连接号连接号用于连接两个类似的词。 以下场合应该使用直线连接号（-），占一个半角字符的位置。 两个名词的复合 图表编号 例句：氧化-还原反应 例句：图 1-1 以下场合应该使用波浪连接号（～），占一个全角字符的位置。 数值范围（例如日期、时间或数字） 例句：2009 年～2011 年 注意，波浪连接号前后两个值都应该加上单位。 波浪连接号也可以用汉字“至”代替。 例句：周围温度：-20°C 至 -10°C 文档体系结构软件手册是一部完整的书，建议采用下面的结构。 简介（Introduction）： [必备] [文件] 提供对产品和文档本身的总体的、扼要的说明 快速上手（Getting Started）：[可选] [文件] 如何最快速地使用产品 入门篇（Basics）： [必备] [目录] 又称”使用篇“，提供初级的使用教程 环境准备（Prerequisite）：[必备] [文件] 软件使用需要满足的前置条件 安装（Installation）：[可选] [文件] 软件的安装方法 设置（Configuration）：[必备] [文件] 软件的设置 进阶篇（Advanced)：[可选] [目录] 又称”开发篇“，提供中高级的开发教程 API（Reference）：[可选] [目录|文件] 软件 API 的逐一介绍 FAQ：[可选] [文件] 常见问题解答 附录（Appendix）：[可选] [目录] 不属于教程本身、但对阅读教程有帮助的内容 Glossary：[可选] [文件] 名词解释 Recipes：[可选] [文件] 最佳实践 Troubleshooting：[可选] [文件] 故障处理 ChangeLog：[可选] [文件] 版本说明 Feedback：[可选] [文件] 反馈方式 下面是两个真实范例，可参考。 Redux 手册 Atom 手册 文件名文档的文件名不得含有空格。 文件名必须使用半角字符，不得使用全角字符。这也意味着，中文不能用于文件名。 错误： 名词解释.md正确： glossary.md 文件名建议只使用小写字母，不使用大写字母。 错误：TroubleShooting.md正确：troubleshooting.md 为了醒目，某些说明文件的文件名，可以使用大写字母，比如README、LICENSE。 文件名包含多个单词时，单词之间建议使用半角的连词线（-）分隔。 不佳：advanced_usage.md正确：advanced-usage.md 参考链接 产品手册中文写作规范, by 华为 写作规范和格式规范, by DaoCloud 技术写作技巧在日汉翻译中的应用, by 刘方 简体中文规范指南, by lengoo 文档风格指南, by LeanCloud 豌豆荚文案风格指南, by 豌豆荚 中文文案排版指北, by sparanoid 中文排版需求, by W3C 为什么文件名要小写？, by 阮一峰]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 索引的创建、删除和查看]]></title>
    <url>%2F2016%2F11%2F15%2Fmysql-index%2F</url>
    <content type="text"><![CDATA[在索引列上，除了有序查找之外，数据库利用各种各样的快速定位技术，能够大大提高查询效率。特别是当数据量非常大，查询涉及多个表时，使用索引往往能使查询速度加快成千上万倍。 例如，有 3 个未索引的表 t1、t2、t3，分别只包含列 c1、c2、c3，每个表分别含有 1000 行数据组成，指为 1～1000 的数值，查找对应值相等行的查询如下所示。 SELECT c1, c2, c3 FROM t1, t2, t3 WHERE c1 = c2 AND c1 = c3 此查询结果应该为 1000 行，每行包含 3 个相等的值。在无索引的情况下处理此查询，必须寻找 3 个表所有的组合，以便得出与 WHERE 子句相配的那些行。而可能的组合数目为 1000 × 1000 × 1000（十亿），显然查询将会非常慢。 如果对每个表进行索引，就能极大地加速查询进程。利用索引的查询处理如下。 （1）从表 t1 中选择第一行，查看此行所包含的数据。 （2）使用表 t2 上的索引，直接定位 t2 中与 t1 的值匹配的行。类似，利用表 t3 上的索引，直接定位 t3 中与来自 t1 的值匹配的行。 （3）扫描表 t1 的下一行并重复前面的过程，直到遍历 t1 中所有的行。 在此情形下，仍然对表 t1 执行了一个完全扫描，但能够在表 t2 和 t3 上进行索引查找直接取出这些表中的行，比未用索引时要快一百万倍。 利用索引，MySQL 加速了 WHERE 子句满足条件行的搜索，而在多表连接查询时，在执行连接时加快了与其他表中的行匹配的速度。 创建索引在执行 CREATE TABLE 语句时可以创建索引，也可以单独用 CREATE INDEX 或 ALTER TABLE 来为表增加索引。 ALTER TABLEALTER TABLE table_name ADD INDEX index_name (column_list)ALTER TABLE table_name ADD UNIQUE (column_list)ALTER TABLE table_name ADD PRIMARY KEY (column_list) 其中 table_name 是要增加索引的表名，column_list 指出对哪些列进行索引，多列时各列之间用逗号分隔。索引名 index_name 可选，缺省时，MySQL 将根据第一个索引列赋一个名称。另外，ALTER TABLE 允许在单个语句中更改多个表，因此可以在同时创建多个索引。 CREATE INDEXCREATE INDEX 可对表增加普通索引或 UNIQUE 索引。 CREATE INDEX index_name ON table_name (column_list)CREATE UNIQUE INDEX index_name ON table_name (column_list) table_name、index_name 和 column_list 具有与 ALTER TABLE 语句中相同的含义，索引名不可选。另外，不能用 CREATE INDEX 语句创建 PRIMARY KEY 索引。 索引类型在创建索引时，可以规定索引能否包含重复值。如果不包含，则索引应该创建为 PRIMARY KEY 或 UNIQUE 索引。对于单列惟一性索引，这保证单列不包含重复的值。对于多列惟一性索引，保证多个值的组合不重复。 PRIMARY KEY 索引和 UNIQUE 索引非常类似。事实上，PRIMARY KEY 索引仅是一个具有名称 PRIMARY 的 UNIQUE 索引。这表示一个表只能包含一个 PRIMARY KEY，因为一个表中不可能具有两个同名的索引。 下面的SQL语句对 students 表在 sid 上添加 PRIMARY KEY 索引。 ALTER TABLE students ADD PRIMARY KEY (sid) 删除索引可利用 ALTER TABLE 或 DROP INDEX 语句来删除索引。类似于 CREATE INDEX 语句，DROP INDEX 可以在 ALTER TABLE 内部作为一条语句处理，语法如下。 DROP INDEX index_name ON talbe_nameALTER TABLE table_name DROP INDEX index_nameALTER TABLE table_name DROP PRIMARY KEY 其中，前两条语句是等价的，删除掉 table_name 中的索引 index_name 。 第 3 条语句只在删除 PRIMARY KEY 索引时使用，因为一个表只可能有一个 PRIMARY KEY 索引，因此不需要指定索引名。如果没有创建 PRIMARY KEY 索引，但表具有一个或多个 UNIQUE 索引，则 MySQL 将删除第一个 UNIQUE 索引。 如果从表中删除了某列，则索引会受到影响。对于多列组合的索引，如果删除其中的某列，则该列也会从索引中删除。如果删除组成索引的所有列，则整个索引将被删除。 查看索引mysql&gt; show index from table_name;mysql&gt; show keys from table_name; Table 表的名称。 Non_unique 如果索引不能包括重复词，则为 0 。如果可以，则为 1 。 Key_name 索引的名称。 Seq_in_index 索引中的列序列号，从 1 开始。 Column_name 列名称。 Collation 列以什么方式存储在索引中。在 MySQL 中，有值 A（升序）或 NULL（无分类）。 Cardinality 索引中唯一值的数目的估计值。通过运行 ANALYZE TABLE 或 myisamchk -a 可以更新。基数根据被存储为整数的统计数据来计数，所以即使对于小型表，该值也没有必要是精确的。基数越大，当进行联合时，MySQL 使用该索引的机会就越大。 Sub_part 如果列只是被部分地编入索引，则为被编入索引的字符的数目。如果整列被编入索引，则为 NULL 。 Packed 指示关键字如何被压缩。如果没有被压缩，则为 NULL 。 Null 如果列含有 NULL，则含有 YES 。如果没有，则该列含有 NO 。 Index_type 用过的索引方法（BTREE，FULLTEXT，HASH，RTREE）。 本文转载自：MySQL索引的创建、删除和查看]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 性能优化]]></title>
    <url>%2F2016%2F09%2F02%2Fmysql-optimization%2F</url>
    <content type="text"><![CDATA[MySQL性能优化的一些建议。 复合索引比如有一条语句是这样的： select * from users where area = 'beijing' and age = 22; 如果我们是在 area 和 age 上分别创建单个索引的话，由于MySQL查询每次只能使用一个索引，所以虽然这样已经相对不做索引时全表扫描提高了很多效率，但是如果在 area、age 两列上创建复合索引的话将带来更高的效率。如果我们创建了 (area, age, salary) 的复合索引，那么其实相当于创建了 (area,age,salary)、(area,age)、(area) 三个索引，这被称为最佳左前缀特性。因此我们在创建复合索引时应该将最常用作限制条件的列放在最左边，依次递减。 索引不会包含有NULL值的列只要列中包含有 NULL 值都将不会被包含在索引中，复合索引中只要有一列含有 NULL 值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为 NULL 。 like语句操作一般情况下不鼓励使用 like 操作，如果非使用不可，如何使用也是一个问题。like “%aaa%” 不会使用索引，而 like “aaa%” 可以使用索引。 不要在列上进行运算select * from users where YEAR(adddate) &lt; 2007; 将在每个行上进行运算，这将导致索引失效而进行全表扫描，因此我们可以改成： select * from users where adddate &lt; ‘2007-01-01’; 不使用NOT IN和&lt;&gt;操作NOT IN 和 &lt;&gt; 操作都不会使用索引将进行全表扫描。NOT IN 可以 NOT EXISTS 代替，id &lt;&gt; 3 则可使用 id &gt; 3 or id &lt; 3 来代替。 不建议使用float、double来存小数为了防止精度丢失，建议使用 decimal 。 高效分页limit m,n 其实是先执行 limit m + n，然后从第 m 行取 n 行，这样当 limit 翻页越往后越大，性能越低，如： select * from users limit 100000, 10; 建议改成： select * from users where id &gt;= (select id from users limit 100000, 1) limit 10; 范围查找范围查找包括 between、大于、小于以及 in 。mysql 中的 in 查询的条件有数量的限制，数量较小可以走索引，数量较大，就成了全表扫描了。而 between、大于、小于等，这些查询不会走索引，所以尽量放在走索引的查询条件后面。 多表链接子查询和 join 都可以实现多张表之间取数据，但是子查询的性能较差，建议使用 join 。对于mysql的 join ，它用的是 Nested Loop Join 算法，也就是通过前一个表查询的结果集去后一个表中查询，比如前一个表的结果集是 100 条数据，后一个表有 10W 数据，就需要在 100 × 10W 的数据集合中取过滤的到最终的结果集，因此，尽量用小结果集的表去和大表做 join ，同时在 join 的字段上建立索引。]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何修复 503 Service Unavailable 错误]]></title>
    <url>%2F2016%2F08%2F24%2F503-service-unavailable%2F</url>
    <content type="text"><![CDATA[本文翻译自: How to Fix a 503 Service Unavailable Error 503 Service Unavailable 是一个 HTTP 状态码，表示 Web 服务器目前不可用。 你可能看到的 503 错误信息网站和服务器软件可以定制 503 错误信息，所以你可能看到不一样的错误信息。 以下是常见的 503 错误信息： 503 Service Unavailable 503 Service Temporarily Unavailable Http/1.1 Service Unavailable HTTP Server Error 503 Service Unavailable - DNS Failure 503 Error HTTP 503 HTTP Error 503 Error 503 Service Unavailable 503 Service Unavailable 错误可能会出现在所有浏览器和所有操作系统上，包括 Window 10 / Window XP，MacOS，Linux等，甚至是你的手机和其他非主流操作系统。只要接入了互联网，那么你就有可能在某些情况下看到 503 错误。浏览器窗口会像显示网页一样显示 503 Service Unavailable 错误。 503 Service Unavailable 的错误原因大多数情况下，导致 503 错误的原因是服务器达到负载或正在进行维护。 Note：使用 Microsoft IIS 的站点可以通过在 503 后面加一个后缀数字来提供有关 503 Service Unavailable 错误原因的更多具体信息，如 HTTP 错误 503.2 - 服务不可用，这意味着超出并发请求限制。 如何修复 503 Service Unavailable503 Service Unavailable 是一个服务端的错误，意味着问题经常出在网站的服务器上，不太可能因为你的电脑的某种问题导致 503 错误。 无论如何，您可以尝试下面几件事情： 通过点击重新加载/刷新按钮或按 F5 再次访问地址栏的 url。 尽管 503 Service Unavailable 错误意味着服务器出现错误，但是这个问题可能只是暂时的，有时只要重新访问该页面就会起作用。 重要提示：如果在支付在线购买时出现 503 Service Unavailable 错误消息，请注意，多次尝试结帐可能会导致创建多个订单，并收取多笔费用！大多数支付系统和一些信用卡公司都有这种情况的保护措施，但仍然需要注意。 重启你的路由器和调制解调器，然后重启你的计算机或设备，尤其是当你看到 “Service Unavailable - DNS Failure” 的时候。 虽然 503 错误最可能是你访问的网站导致的，但也有可能是你的路由器或计算机上的 DNS 服务器配置有问题，这两个简单的重启可能会修复这个问题。 提示：如果重启设备没有修复 503 DNS Failure 错误，那么可能是 DNS 服务器本身出现了临时问题。在这种情况下，从 免费和公共DNS服务器列表 中选择新的 DNS 服务器，并在计算机或路由器上进行修改。如果需要帮助，请参阅 如何更改DNS服务器 。 另一个选择是直接联系网站寻求帮助。网站的管理员很有可能已经知道 503 错误，但告知他们检查问题的状态，这不是一个坏主意。 有关热门网站的联系信息，请参阅 网站联系信息列表 。大多数网站都有基于支持的社交网络帐户，有些甚至有电话号码和电子邮件地址。 稍后再访问。当访问者流量大幅增加导致服务器负载的时候，经常会出现 503 Service Unavailable 错误，这时候只需要等待一段时间再访问。随着越来越多的访问者离开网站，您的页面加载成功的可能性将会增加。]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode 常用快捷键]]></title>
    <url>%2F2016%2F07%2F21%2Fvscode-hot-key%2F</url>
    <content type="text"><![CDATA[VSCode 的快捷键继承了一些 IDE 风格，有 VS 的身影，也有 Emacs 的身影。简言之，内置快捷键玩熟了，效率提高不是一点两点。 窗口 操作 快捷键 打开文件 Ctrl + O 打开文件夹 Ctrl + K + O 保存文件 Ctrl + S 另存为 Ctrl + Shift + S 新建文件 Ctrl + N 关闭当前文件 Ctrl + W 或 Ctrl + F4 关闭所有编辑窗口 Ctrl + K + W 打开新编辑器 Ctrl + Shift + N 关闭编辑器 Ctrl + Shift + W 撤销最近关闭的一个文件编辑窗口 Ctrl + Shift + T 切换打开的文件 Ctrl + Tab 快速切换文件，可搜索 Ctrl + E 或 Ctrl + P 切换标签页的位置 Ctrl + Shift + PgUp / PgDown 多个编辑窗口 Ctrl + 1 Ctrl + 2 Ctrl + 3 或 Ctrl + \ 或 Ctrl + Click file 代码编辑 操作 快捷键 代码行缩进 Ctrl + [、Ctrl + ] 折叠/展开区域代码 Ctrl + Shift + [、Ctrl + Shift + ] 折叠/展开所有子区域代码 Ctrl + K + [、Ctrl + K + ] 折叠/展开所有区域代码 Ctrl + K + 0、Ctrl + K + J 注释/取消注释 Ctrl + / 块区域注释 Shift + Alt + A 添加函数注释 Ctrl + Alt + D + D 选中当前行 Ctrl + i 删除当前行 Ctrl + Shift + K 或 Shift + Delete 删除光标右侧的单词 Ctrl + Delete 在当前行下边插入一行 Ctrl + Enter 在当前行上方插入一行 Ctrl + Shift + Enter 历史文件切换 Alt + Left / Right 当前代码行上下移动 Alt + Up / Down 向上向下复制一行 Shift + Alt + Up / Down 视图上下偏移 Ctrl + Up / Down 跳转到上一个 / 下一个错误或者警告 F8 / Shift + F8 光标相关 操作 快捷键 移动到行首 Home 移动到行尾 End 选择从光标到行首 Shift + Home 选择从光标到行尾 Shift + End 移动到文件开头 Ctrl + Home 移动到文件结尾 Ctrl + End 跳转到指定行 Ctrl + G 扩展选取范围 Shift + Alt + Right 缩小选取范围 Shift + Alt + Left 匹配并跳转到花括号的闭合处 Ctrl + Shift + \ 插入光标-支持多个 Alt + Click 上下插入光标-支持多个 Shift + Alt + Click 或 Ctrl + Alt + Up / Down 撤销最后一次光标操作 Ctrl + U 插入光标到选中范围内所有行结束符 Shift + Alt + i 插入光标到所有匹配到的末尾 Ctrl + Shift + L 查询与替换 操作 快捷键 当前文件中查找 Ctrl + F 整个文件夹中查找 Ctrl + Shift + F 下一个 / 上一个查询结果 F3 / Shift + F3 选中所有出现在查询中的 Alt + Enter 当前文件中查找替换 Ctrl + H 整个文件夹中查找替换 Ctrl + Shift + H 语言操作 操作 快捷键 Emmet指令触发 / 缩进 Tab 格式化代码 Shift + Alt + F 格式化选中部分的代码 Ctrl + K + F 跳转到定义处 F12 查看定义处缩略图 Alt + F12 查看引用 Shift + F12 在其他窗口打开定义处 Ctrl + K + F12 快速修复部分可以修复的语法错误 Ctrl + . 重命名符号以及所有引用 F2 移除空白字符 Ctrl + K + X 显示 操作 快捷键 打开命令面板 F1 或 Ctrl + Shift + P 全屏 F11 放大 / 缩小字体 Ctrl + = / Ctrl + - 预览markdown Ctrl + Shift + V 显示 / 隐藏侧边栏 Ctrl + B 打开资源视图 Ctrl + Shift + E 打开全局搜索 Ctrl + Shift + F 打开 Git 可视管理 Ctrl + Shift + G 打开 DeBug 面板 Ctrl + Shift + D 打开插件市场面板 Ctrl + Shift + X 打开问题面板 Ctrl + Shift + M 打开输出面板 Ctrl + Shift + U 打开调试控制台面板 Ctrl + Shift + Y 调试 操作 快捷键 启动调试、继续 F5 添加 / 删除断点 F9 单步跳过 F10 单步进入 / 单步跳出 F11 / Shift + F11 显示悬浮 Ctrl + k + i 集成终端 操作 快捷键 打开集成终端 Ctrl + ` 创建一个新的终端 Ctrl + Shift + ` 页面上下翻屏 Shift + PgUp / PgDown 滚动到页面头部或尾部 Ctrl + Home / End 其他 操作 快捷键 修改主题 F1 后输入 theme 回车，然后上下键即可预览 修改默认快捷键 File -&gt; Preferences -&gt; Keyboard Shortcuts]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>VS Code</tag>
        <tag>editor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何编写一个 json 对象的拷贝函数]]></title>
    <url>%2F2016%2F07%2F18%2Fdeep-shallow%2F</url>
    <content type="text"><![CDATA[浅拷贝，比如浅拷贝对象A时，对象B将拷贝A的所有属性，如果属性是引用类型，B将拷贝地址，若果属性是基本类型，B将复制其值。浅拷贝的缺点是如果你修改了对象B中引用类型属性，你同时也会影响到对象A。 深拷贝会完全拷贝所有数据，优点是拷贝双方不会相互依赖，比如修改了一方的引用类型属性，不会影响到另一方。缺点是拷贝的速度更慢，代价更大 （我的理解是耗费了更多内存空间）。 浅拷贝实现1、使用 ES6 的 Object.assign，其内部实现就是浅拷贝，并剔除了目标对象的原型方法 let a = &#123; p: [1, 2]&#125;;let b = Object.assign(&#123;&#125;, a);console.log(b.p == a.p); 2、遍历对象属性 function shallowClone(obj) &#123; if (!obj || typeof obj !== 'object') &#123; throw new Error('error arguments'); &#125; let targetObj = obj.constructor === Array ? [] : &#123;&#125;; for (let key in obj) &#123; if (obj.hasOwnProperty(key)) &#123; targetObj[key] = obj[key]; &#125; &#125; return targetObj;&#125; 深拷贝实现1、利用 JSON 序列化实现一个深拷贝，缺点是无法复制函数，并且丢失抛弃对象的 constructor 和原型链 function deepClone(obj) &#123; return JSON.parse(JSON.stringify(obj));&#125;let o1 = &#123; arr: [1, 2, 3], obj: &#123; key: 'value' &#125;, func()&#123; return 1; &#125;&#125;;let o2 = deepClone(o1);console.log(o2); // =&gt; &#123;arr: [1,2,3], obj: &#123;key: 'value'&#125;&#125; 2、利用递归实现深拷贝，可以复制函数，同样会丢失抛弃对象的 constructor 和原型链，但是对于拷贝 json 对象的话足够了 function deepCopy(src) &#123; if(!src || typeof src !== 'object')&#123; throw new Error('error arguments'); &#125; let target = src.constructor === Array ? [] : &#123;&#125;; for (let i in src) &#123; if (typeof src[i] === 'object') &#123; target[i] = src[i].constructor === Array ? [] : &#123;&#125;; target[i] = deepCopy(src[i]); &#125; else &#123; target[i] = src[i]; &#125; &#125; return target;&#125; 参考：深入剖析 JavaScript 的深复制]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome 常用快捷键]]></title>
    <url>%2F2016%2F06%2F21%2Fchrome-hot-key%2F</url>
    <content type="text"><![CDATA[Chrome 的一些常用快捷键。 窗口与标签页 操作 快捷键 打开新窗口 Ctrl + n 在隐身模式下打开新窗口 Ctrl + Shift + n 打开新的标签页 Ctrl + t 恢复最后关闭的标签页 Ctrl + Shift + t 关闭当前标签页 Ctrl + w 或 Ctrl + F4 关闭所有打开的标签页和浏览器 Ctrl + Shift + w 跳转到下一个打开的标签页 Ctrl + Tab 或 Ctrl + PgDn 跳转到上一个打开的标签页 Ctrl + Shift + Tab 或 Ctrl + PgUp 跳转到特定标签页 Ctrl + 1 到 Ctrl + 8 跳转到最后一个标签页 Ctrl + 9 在当前标签页中打开主页 Alt + Home 最小化当前窗口 Alt + 空格键 + n 最大化当前窗口 Alt + 空格键 + x 开启或关闭全屏模式 F11 退出 Chrome Alt + F4 或 Ctrl + Shift + q 网页操作 操作 快捷键 重新加载当前网页 F5 或 Ctrl + r 重新加载当前网页（忽略缓存的内容） Shift + F5 或 Ctrl + Shift + r 停止加载网页 Esc 打开查找栏搜索当前网页 Ctrl + f 或 F3 跳转到与查找栏中搜索字词相匹配的下一条内容 Ctrl + g 跳转到与查找栏中搜索字词相匹配的上一条内容 Ctrl + Shift + g 将当前网页保存为书签 Ctrl + d 将所有打开的标签页保持为书签 Ctrl + Shift + d 显示或隐藏书签栏 Ctrl + Shift + b 放大网页上的所有内容 Ctrl + + 或 按住 Ctrl 键的同时向上滚动鼠标滚轮 缩小网页上的所有内容 Ctrl + - 或 按住 Ctrl 键的同时向下滚动鼠标滚轮 将网页上的所有内容恢复到默认大小 Ctrl + 0 将焦点放置在 Chrome 工具栏中的第一项上 Shift + Alt + t 浏览下一个可点击项 Tab 浏览上一个可点击项 Shift + Tab 向下滚动网页，一次一个屏幕 空格键或 PgDn 向上滚动网页，一次一个屏幕 Shift + 空格键或 PgUp 在网页上水平滚动 按住 Shift 键并滚动鼠标滚轮 删除文本字段中的上一个字词 Ctrl + Backspace 将焦点移到通知上 Alt + n 在通知中允许 Alt + Shift + a 在通知中拒绝 Alt + Shift + d 显示当前网页的 HTML 源代码（不可修改） Ctrl + u 使用 Chrome 打开计算机中的文件 按住 Ctrl + o 键并选择文件 打印当前网页 Ctrl + p 保存当前网页 Ctrl + s 地址栏操作 操作 快捷键 使用默认搜索引擎进行搜索 输入搜索字词并按 Enter 键 使用其他搜索引擎进行搜索 输入搜索引擎名称并按 Tab 键 为网站名称添加 www. 和 .com，并在当前标签页中 / 新标签页中打开该网站 输入网站名称并按 Ctrl + Enter 键 / Alt + Enter 键 跳转到地址栏 Ctrl + l、Alt + d 或 F6 在地址栏、书签栏和页面内容之间向前/向后切换焦点 F6 / Shift + F6 从页面中的任意位置搜索 Ctrl + k 或 Ctrl + e 其他功能 操作 快捷键 打开“菜单” Alt + e 或 F10 打开开发者工具 Ctrl + Shift + j 或 F12 打开清除浏览数据选项 Ctrl + Shift + Delete 打开书签管理器 Ctrl + Shift + o 打开历史记录页 Ctrl + h 打开下载内容页 Ctrl + j 打开 Chrome 帮助中心 F1 打开 Chrome 任务管理器 Shift + Esc 使用其他帐户登录或进入隐身模式 Ctrl + Shift + m]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>Chrome</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 博客搭建]]></title>
    <url>%2F2016%2F06%2F19%2Fhexo-blog%2F</url>
    <content type="text"><![CDATA[作为一名开发人员，一直以来都很想拥有一个个人博客，来和世界分享自己的所见所得。在了解 hexo 后，惊叹于 hexo 搭建个人博客的快速、高效，以及各类丰富的博客主题。千挑万选之下选择了十分简洁大气的 maupassant-hexo 主题，下面是我搭建 maupassant-hexo 主题博客的全过程。 安装 Hexo安装前提： Node.js Git 使用 npm 进行 hexo 的全局安装： npm install -g hexo-cli 创建 Hexo 根目录，&lt;folder&gt;为目录名： hexo init &lt;folder&gt; 进入 Hexo 根目录，通过hexo server命令启动服务器，默认的访问地址是：http://localhost:4000，然后就可以看到 hexo 默认主题的页面。 安装 maupassant-hexo 主题在 Hexo 根目录下执行下面的命令，安装主题和渲染器： git clone https://github.com/tufu9441/maupassant-hexo.git themes/maupassantnpm install hexo-renderer-jade@0.3.0 --savenpm install hexo-renderer-sass --save 编辑 Hexo 根目录下的_config.yml，将theme的值改为maupassant，然后就可以删除themes目录下的默认主题landscape了。 注：如果 npm install hexo-renderer-sass 安装时报错，可能是国内网络问题，请尝试使用代理或者切换至淘宝NPM镜像安装。 然后在 Hexo 根目录下执行hexo server命令，就可以访问到maupassant-hexo主题的页面了。到此本地的博客就算搭建完成了，进一步的配置参考官方文档： Hexo 配置 maupassant-hexo 中文文档 基本操作# 添加文章hexo new [layout] &lt;title&gt; 如果没有设置 layout 的话，默认使用_config.yml中的default_layout参数代替。如果标题包含空格的话，请使用引号括起来。新建的文章存放在 Hexo 根目录的source/_posts下，也可以手动在source/_posts目录下添加文章。 # 添加分类 / 标签在 Front-matter 中添加categories或tags的配置，在右边的侧边栏就会添加对应的分类或标签。 ---title: Hexo 博客搭建 date: 2017-07-19 23:11:39tags: 博客搭建category: 技术--- # 添加 RSS 订阅功能在 Hexo 根目录下执行下面命令，安装hexo-generator-feed: npm install hexo-generator-feed --save 在 Hexo 根目录下的_config.yml中添加 RSS 订阅的配置： feed: type: atom path: atom.xml limit: 20 # 删除友情链接注释主题目录下_config.yml中友情链接的配置，如下： # links:# - title: site-name1# url: http://www.example1.com/# - title: site-name2# url: http://www.example2.com/# - title: site-name3# url: http://www.example3.com/ # 更换中文编辑 Hexo 根目录下的_config.yml，将language设置为zh-CN。]]></content>
      <categories>
        <category>码梦为生</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
      </tags>
  </entry>
</search>
